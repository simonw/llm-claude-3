interactions:
- request:
    body: null
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Authorization:
      - Bearer ffa41c60548d5bb59f5224a045654ba928cef36211dc7534682086ee60ee9a9a
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      User-Agent:
      - TogetherPythonOfficial/0.2.9
    method: GET
    uri: https://api.together.xyz/models/info?=
  response:
    body:
      string: "[{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6de95e620478cfa144261\",\"name\":\"codellama/CodeLlama-34b-Instruct-hf\",\"display_name\":\"Code
        Llama Instruct (34B)\",\"display_type\":\"chat\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"LLAMA 2 Community
        license Agreement (Meta)\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":34000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":16384,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"add_generation_prompt\":true,\"stop\":[\"</s>\",\"[INST]\"],\"chat_template_name\":\"llama\",\"tools_template\":\"{{
        '<<SYS>>\\\\n' + systemMessage['content'] + '\\\\n\\\\nYou can access the
        following functions. Use them if required -\\\\n' + tools + '\\\\n<</SYS>>\\\\n\\\\n'
        + message['content'] }}\"},\"pricing\":{\"input\":194,\"output\":194,\"hourly\":0},\"created_at\":\"2023-08-24T17:28:42.172Z\",\"update_at\":\"2023-08-24T17:28:42.172Z\",\"instances\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\"}],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"657f7552a9c4049b6a42e4c6\",\"name\":\"upstage/SOLAR-10.7B-Instruct-v1.0\",\"display_name\":\"Upstage
        SOLAR Instruct v1 (11B)\",\"display_type\":\"chat\",\"description\":\"Built
        on the Llama2 architecture, SOLAR-10.7B incorporates the innovative Upstage
        Depth Up-Scaling\",\"license\":\"cc-by-nc-4.0\",\"creator_organization\":\"upstage\",\"pricing_tier\":\"Featured\",\"num_parameters\":10700000000,\"release_date\":\"2023-12-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":4096,\"config\":{\"add_generation_prompt\":true,\"stop\":[\"</s>\",\"###\"],\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'system' %}{% if message['content']%}{{'###
        System:\\n' + message['content']+'\\n\\n'}}{% endif %}{% elif message['role']
        == 'user' %}{{'### User:\\n' + message['content']+'\\n\\n'}}{% elif message['role']
        == 'assistant' %}{{'### Assistant:\\n'  + message['content']}}{% endif %}{%
        if loop.last and add_generation_prompt %}{{ '### Assistant:\\n' }}{% endif
        %}{% endfor %}\"},\"pricing\":{\"input\":75,\"output\":75},\"created_at\":\"2023-12-17T22:25:22.252Z\",\"update_at\":\"2023-12-17T22:32:58.075Z\",\"instances\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\"}],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\",\"capacity\":0.023255813953488372,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6577bf1034e6c1e2bb5283d9\",\"name\":\"mistralai/Mixtral-8x7B-v0.1\",\"display_name\":\"Mixtral-8x7B
        v0.1\",\"display_type\":\"language\",\"description\":\"The Mixtral-8x7B Large
        Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.\",\"license\":\"apache-2.0\",\"link\":\"https://huggingface.co/mistralai/Mixtral-8x7B-v0.1\",\"creator_organization\":\"mistralai\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":56000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"pricing\":{\"input\":150,\"output\":150,\"hourly\":0},\"created_at\":\"2023-12-12T02:01:52.674Z\",\"update_at\":\"2024-02-08T07:58:39.848Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"instances\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"}],\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.07142857142857142,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"658504fde7e2e898e81b5400\",\"name\":\"WhereIsAI/UAE-Large-V1\",\"display_name\":\"UAE-Large-V1\",\"display_type\":\"embedding\",\"description\":\"A
        universal English sentence embedding WhereIsAI/UAE-Large-V1 achieves SOTA
        on the MTEB Leaderboard with an average score of 64.64!\",\"license\":\"apache-2.0\",\"link\":\"https://huggingface.co/bert-base-uncased\",\"creator_organization\":\"WhereIsAI\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":330000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"pricing\":{\"hourly\":0,\"input\":4,\"output\":4,\"finetune\":0,\"base\":0},\"created_at\":\"2023-12-22T03:39:41.105Z\",\"update_at\":\"2023-12-22T03:45:34.219Z\",\"instances\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\"}],\"lago_tag\":\"metricTag:EMBEDDING_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\",\"capacity\":0.0078125,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669f0a0b271f67e4e4c278e0\",\"name\":\"meta-llama/Meta-Llama-Guard-3-8B\",\"display_name\":\"Meta
        Llama Guard 3 8B\",\"display_type\":\"moderation\",\"description\":\"\",\"license\":\"llama\",\"link\":null,\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"context_length\":8192,\"config\":{\"chat_template\":\"{%
        if messages.length % 2 == 0 %}{% set final_role = 'Agent' %}{% else %}{% set
        final_role = 'User' %}{% endif %}<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nTask:
        Check if there is unsafe content in '{{ final_role }}' messages in conversations
        according our safety policy with the below categories.\\n\\n<BEGIN UNSAFE
        CONTENT CATEGORIES>\\nS1: Violent Crimes.\\nS2: Non-Violent Crimes.\\nS3:
        Sex Crimes.\\nS4: Child Exploitation.\\nS5: Defamation.\\nS6: Specialized
        Advice.\\nS7: Privacy.\\nS8: Intellectual Property.\\nS9: Indiscriminate Weapons.\\nS10:
        Hate.\\nS11: Self-Harm.\\nS12: Sexual Content.\\nS13: Elections.\\nS14: Code
        Interpreter Abuse.\\n<END UNSAFE CONTENT CATEGORIES>\\n\\n<BEGIN CONVERSATION>\\n\\n{%
        for message in messages %}{% if message['role'] == 'user' and loop.index0
        % 2 == 0 %}User: {{ message['content'].trim() }}{% elif message['role'] ==
        'assistant' and loop.index0 % 2 != 0 %}Agent: {{ message['content'].trim()
        }}{% else %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...')
        }}{% endif %}{% if loop.last %}{% set role = message['role'] %}{% endif %}{{
        '\\n\\n' }}{% endfor %}<END CONVERSATION>\\n\\nProvide your safety assessment
        for {{ role }} in the above conversation:\\n - First line must read 'safe'
        or 'unsafe'.\\n - If unsafe, a second line must include a comma-separated
        list of violated categories.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\",\"safety_label\":\"safe\",\"safe_response\":true,\"safety_config\":{\"max_tokens\":64},\"safety_categories\":{\"S1\":\"Violent
        Crimes\",\"S2\":\"Non-Violent Crimes\",\"S3\":\"Sex Crimes\",\"S4\":\"Child
        Exploitation\",\"S5\":\"Defamation\",\"S6\":\"Specialized Advice\",\"S7\":\"Privacy\",\"S8\":\"Intellectual
        Property\",\"S9\":\"Indiscriminate Weapons\",\"S10\":\"Hate\",\"S11\":\"Self-Harm\",\"S12\":\"Sexual
        Content\",\"S13\":\"Elections\",\"S14\":\"Code Interpreter Abuse\"}},\"pricing\":{\"hourly\":0,\"input\":50,\"output\":50},\"created_at\":\"2024-04-18T08:36:20.125Z\",\"update_at\":\"2024-05-15T20:38:23.297Z\",\"instances\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\"}],\"isPrivate\":false,\"access_control\":[{\"user_id\":\"65776b1c6943bff034b2248f\",\"role\":\"admin\"},{\"user_id\":\"63b8c450fc5f8b00a9eb88be\",\"role\":\"admin\"},{\"user_id\":\"65503d59c4e8d25c07854c0b\",\"role\":\"admin\"},{\"user_id\":\"63b46d7f108537a03cf0e2a4\",\"role\":\"admin\"},{\"user_id\":\"665e248837cb8a07b7dbd3cc\",\"role\":\"admin\"}],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\",\"capacity\":1,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6585058be7e2e898e81b5401\",\"name\":\"togethercomputer/m2-bert-80M-32k-retrieval\",\"display_name\":\"M2-BERT-Retrieval-32k\",\"display_type\":\"embedding\",\"description\":\"The
        80M checkpoint for M2-BERT-base from the paper Monarch Mixer: A Simple Sub-Quadratic
        GEMM-Based Architecture with sequence length 8192, and it has been fine-tuned
        for retrieval.\",\"license\":\"apache-2.0\",\"link\":\"https://huggingface.co/togethercomputer/m2-bert-80M-32k-retrieval\",\"creator_organization\":\"Together\",\"hardware_label\":\"L40\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":80000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"pricing\":{\"hourly\":0,\"input\":2,\"output\":2,\"finetune\":0,\"base\":0},\"created_at\":\"2023-11-04T17:57:24.532Z\",\"update_at\":\"2023-11-04T17:57:24.532Z\",\"instances\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\"}],\"lago_tag\":\"metricTag:EMBEDDING_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\",\"capacity\":0.0078125,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6560b993b56cf1e0970c9b1a\",\"name\":\"BAAI/bge-base-en-v1.5\",\"display_name\":\"BAAI-Bge-Base-1p5\",\"display_type\":\"embedding\",\"description\":\"bge
        is short for BAAI general embedding, it maps any text to a low-dimensional
        dense vector using FlagEmbedding\",\"license\":\"MIT\",\"creator_organization\":\"BAAI\",\"hardware_label\":\"A40\",\"pricing_tier\":\"Featured\",\"num_parameters\":109482240,\"release_date\":\"2023-11-15T00:00:00.000Z\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"pricing\":{\"hourly\":0,\"input\":2,\"output\":2,\"finetune\":0,\"base\":0},\"created_at\":\"2023-11-24T14:56:19.475Z\",\"update_at\":\"2024-08-30T06:08:14.651Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\"}],\"isPrivate\":false,\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:EMBEDDING_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":61.4,\"throughput_in\":3497.266666666667,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\",\"capacity\":0.015391417512012813,\"qps\":61.4,\"throughput_in\":3497.266666666667,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6553b8da6664bf7229b2dbfb\",\"name\":\"togethercomputer/m2-bert-80M-2k-retrieval\",\"display_name\":\"M2-BERT-Retrieval-2K\",\"display_type\":\"embedding\",\"description\":\"M2-BERT
        from the Monarch Mixer paper fine-tuned for retrieval\",\"license\":\"Apache-2\",\"creator_organization\":\"Together\",\"hardware_label\":\"L40\",\"pricing_tier\":\"Featured\",\"num_parameters\":80000000,\"release_date\":\"2023-11-01T00:00:00.000Z\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"pricing\":{\"hourly\":0,\"input\":2,\"output\":2,\"finetune\":0,\"base\":0},\"created_at\":\"2023-11-14T18:13:46.901Z\",\"update_at\":\"2024-08-30T06:10:05.638Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\"}],\"isPrivate\":false,\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:EMBEDDING_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\",\"capacity\":0.0078125,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"658c8dad27fb98d2edc447ff\",\"name\":\"NousResearch/Nous-Hermes-2-Yi-34B\",\"display_name\":\"Nous
        Hermes-2 Yi (34B)\",\"display_type\":\"chat\",\"description\":\"Nous Hermes
        2 - Yi-34B is a state of the art Yi Fine-tune\",\"license\":\"apache-2\",\"creator_organization\":\"NousResearch\",\"hardware_label\":\"A100\",\"pricing_tier\":\"Featured\",\"num_parameters\":34000000000,\"release_date\":\"2023-12-27T20:48:45.586Z\",\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":4096,\"config\":{\"stop\":[\"<|im_start|>\",\"<|im_end|>\"],\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"chat_template_name\":\"default\",\"add_generation_prompt\":true},\"pricing\":{\"input\":200,\"output\":200},\"created_at\":\"2023-12-27T20:48:45.586Z\",\"update_at\":\"2023-12-27T20:50:38.632Z\",\"instances\":[{\"avzone\":\"ap-northeast-1a\",\"cluster\":\"optimisticotter\"}],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.13333333333333333,\"throughput_in\":36.06666666666667,\"throughput_out\":3.533333333333333,\"stats\":[{\"avzone\":\"ap-northeast-1a\",\"cluster\":\"optimisticotter\",\"capacity\":0.028490028490028487,\"qps\":0.13333333333333333,\"throughput_in\":36.06666666666667,\"throughput_out\":3.533333333333333,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6560b938b56cf1e0970c9b19\",\"name\":\"BAAI/bge-large-en-v1.5\",\"display_name\":\"BAAI-Bge-Large-1p5\",\"display_type\":\"embedding\",\"description\":\"bge
        is short for BAAI general embedding, it maps any text to a low-dimensional
        dense vector using FlagEmbedding\",\"license\":\"MIT\",\"creator_organization\":\"BAAI\",\"hardware_label\":\"A40\",\"pricing_tier\":\"Featured\",\"num_parameters\":335141888,\"release_date\":\"2023-11-15T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":true,\"pricing\":{\"hourly\":0,\"input\":4,\"output\":4,\"finetune\":0,\"base\":0},\"created_at\":\"2023-11-24T14:54:48.986Z\",\"update_at\":\"2023-12-22T03:27:18.465Z\",\"instances\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\"}],\"lago_tag\":\"metricTag:EMBEDDING_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\",\"capacity\":0.0078125,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66313f416fbdf5d304b833d1\",\"name\":\"togethercomputer/Llama-3-8b-chat-hf-int4\",\"display_name\":\"Llama3
        8B Chat HF INT4\",\"display_type\":\"chat\",\"description\":\"Llama 3 is an
        auto-regressive language model that uses an optimized transformer architecture.
        The tuned versions use supervised fine-tuning (SFT) and reinforcement learning
        with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"owner_userid\":null,\"parent\":\"meta-llama/Llama-3-8b-chat-hf\",\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-04-18T06:07:59.041Z\",\"update_at\":\"2024-04-24T19:14:26.075Z\",\"instances\":[{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"}],\"isPrivate\":true,\"access_control\":[],\"isDedicatedInstance\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65735d536923087ddd5a6606\",\"name\":\"togethercomputer/StripedHyena-Nous-7B\",\"display_name\":\"StripedHyena
        Nous (7B)\",\"display_type\":\"chat\",\"description\":\"A hybrid architecture
        composed of multi-head, grouped-query attention and gated convolutions arranged
        in Hyena blocks, different from traditional decoder-only Transformers\",\"license\":\"Apache-2\",\"creator_organization\":\"Together\",\"hardware_label\":\"H100\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"release_date\":\"2023-11-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"config\":{\"stop\":[\"###\",\"</s>\"],\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n\\n### Response:\",\"chat_template\":\"{% for message
        in messages %}{% if message['role'] == 'user' %}{{ bos_token + '### Instruction:\\\\n'
        + message['content'] + '\\\\n\\\\n' }}{% elif message['role'] == 'system'
        %}{{ '### System:\\\\n' + message['content'] + '\\\\n\\\\n' }}{% elif message['role']
        == 'assistant' %}{{ '### Response:\\\\n'  + message['content'] + '\\\\n' }}{%
        endif %}{% if loop.last %}{{ '### Response:\\\\n' }}{% endif %}{% endfor %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50},\"created_at\":\"2023-12-08T18:15:47.433Z\",\"update_at\":\"2023-12-08T19:03:11.497Z\",\"instances\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\"}],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\",\"capacity\":0.05263157894736842,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65d7e89e03b97802d3af0512\",\"name\":\"google/gemma-2b-it\",\"display_name\":\"Gemma
        Instruct (2B)\",\"display_type\":\"chat\",\"description\":\"Gemma is a family
        of lightweight, state-of-the-art open models from Google, built from the same
        research and technology used to create the Gemini models.\",\"license\":\"gemma-terms-of-use\",\"link\":\"https://huggingface.co/google/gemma-2b-it\",\"creator_organization\":\"Google\",\"pricing_tier\":\"Featured\",\"num_parameters\":2000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":8192,\"config\":{\"stop\":[\"<eos>\",\"<end_of_turn>\"],\"chat_template\":\"{{
        bos_token }}{% if (message['role'] == 'assistant') %}{% set role = 'model'
        %}{% else %}{% set role = message['role'] %}{% endif %}{% for message in messages
        %}{{'<start_of_turn>' + role + '\\n' + message['content'] + '<end_of_turn>'
        + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>model\\n'
        }}{% endif %}\",\"bos_token\":\"<bos>\"},\"pricing\":{\"input\":25,\"output\":25,\"hourly\":0},\"created_at\":\"2024-02-23T00:36:46.381Z\",\"update_at\":\"2024-02-23T00:36:46.381Z\",\"instances\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\"}],\"isPrivate\":false,\"access_control\":[],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\",\"capacity\":0.0078125,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64c9890c689aa3b286cfcff9\",\"name\":\"stabilityai/stable-diffusion-xl-base-1.0\",\"display_name\":\"Stable
        Diffusion XL 1.0\",\"display_type\":\"image\",\"description\":\"A text-to-image
        generative AI model that excels at creating 1024x1024 images.\",\"license\":\"openrail++\",\"link\":\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0\",\"creator_organization\":\"Stability
        AI\",\"hardware_label\":\"A100 80GB\",\"pricing_tier\":\"featured\",\"access\":\"open\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"external_pricing_url\":\"https://www.together.xyz/apis#pricing\",\"config\":{\"height\":1024,\"width\":1024,\"number_of_images\":4,\"steps\":40,\"seed\":1000,\"optimized\":{\"512x512\":\"-512-576-1024\",\"576x1024\":\"-512-576-1024\",\"1024x576\":\"-512-576-1024\",\"1024x1024\":\"-512-576-1024\"}},\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0,\"finetune\":0,\"base\":0},\"created_at\":\"2023-08-01T22:37:00.851Z\",\"update_at\":\"2024-05-29T02:11:47.134Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-west-1a\",\"cluster\":\"curiouscrow\"}],\"isPrivate\":false,\"isDedicatedInstance\":false,\"engine\":\"image\",\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-west-1a\",\"cluster\":\"curiouscrow\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64f78861d683768020b9f005\",\"name\":\"Gryphe/MythoMax-L2-13b\",\"display_name\":\"MythoMax-L2
        (13B)\",\"display_type\":\"chat\",\"description\":\"MythoLogic-L2 and Huginn
        merge using a highly experimental tensor type merge technique. The main difference
        with MythoMix is that I allowed more of Huginn to intermingle with the single
        tensors located at the front and end of a model\",\"license\":\"other\",\"creator_organization\":\"Gryphe\",\"hardware_label\":\"1x
        A40 48GB\",\"num_parameters\":13000000000,\"release_date\":\"2023-08-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\"],\"add_generation_prompt\":true,\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n### Response:\",\"chat_template\":\"{% for message
        in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' +
        message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-09-05T19:58:25.683Z\",\"update_at\":\"2023-09-05T19:58:25.683Z\",\"instances\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\"}],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":4.733333333333333,\"throughput_in\":4899.866666666667,\"throughput_out\":466.6666666666667,\"stats\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\",\"capacity\":0.04193832599118932,\"qps\":4.733333333333333,\"throughput_in\":4899.866666666667,\"throughput_out\":466.6666666666667,\"error_rate\":0.06666666666666667,\"retry_rate\":0}],\"error_rate\":0.06666666666666667,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66215c615f70248d1cd89d9f\",\"name\":\"meta-llama/LlamaGuard-2-8b\",\"display_name\":\"Meta
        Llama Guard 2 8B\",\"display_type\":\"moderation\",\"description\":\"\",\"license\":\"Llama-3
        (Other)\",\"link\":null,\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"context_length\":8192,\"owner_userid\":null,\"config\":{\"chat_template\":\"{%
        if messages.length % 2 == 0 %}{% set final_role = 'Agent' %}{% else %}{% set
        final_role = 'User' %}{% endif %}[INST] Task: Check if there is unsafe content
        in '{{ final_role }}' messages in conversations according our safety policy
        with the below categories.\\n\\n<BEGIN UNSAFE CONTENT CATEGORIES>\\nS1: Violent
        Crimes.\\nS2: Non-Violent Crimes.\\nS3: Sex Crimes.\\nS4: Child Exploitation.\\nS5:
        Specialized Advice.\\nS6: Privacy.\\nS7: Intellectual Property.\\nS8: Indiscriminate
        Weapons.\\nS9: Hate.\\nS10: Self-Harm.\\nS11: Sexual Content.\\n<END UNSAFE
        CONTENT CATEGORIES>\\n\\n<BEGIN CONVERSATION>\\n\\n{% for message in messages
        %}{% if message['role'] == 'user' and loop.index0 % 2 == 0 %}User: {{ message['content'].trim()
        }}{% elif message['role'] == 'assistant' and loop.index0 % 2 != 0 %}Agent:
        {{ message['content'].trim() }}{% else %}{{ raise_exception('Conversation
        roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if
        loop.last %}{% set role = message['role'] %}{% endif %}{{ '\\n\\n' }}{% endfor
        %}<END CONVERSATION>\\n\\nProvide your safety assessment for ONLY THE LAST
        {{ role }} message in the above conversation:\\n - First line must read 'safe'
        or 'unsafe'.\\n - If unsafe, a second line must include a comma-separated
        list of violated categories. [/INST]\",\"safety_label\":\"safe\",\"safe_response\":true,\"safety_config\":{\"max_tokens\":64},\"safety_categories\":{\"S1\":\"Violent
        Crimes\",\"S2\":\"Non-Violent Crimes\",\"S3\":\"Sex Crimes\",\"S4\":\"Child
        Exploitation\",\"S5\":\"Specialized Advice\",\"S6\":\"Privacy\",\"S7\":\"Intellectual
        Property\",\"S8\":\"Indiscriminate Weapons\",\"S9\":\"Hate\",\"S10\":\"Self-Harm\",\"S11\":\"Sexual
        Content\"}},\"pricing\":{\"hourly\":0,\"input\":50,\"output\":50},\"created_at\":\"2024-04-18T08:36:20.125Z\",\"update_at\":\"2024-05-15T20:38:23.297Z\",\"instances\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":23.733333333333334,\"throughput_in\":17090.866666666665,\"throughput_out\":60.13333333333333,\"stats\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\",\"capacity\":0.05128543177323654,\"qps\":23.733333333333334,\"throughput_in\":17090.866666666665,\"throughput_out\":60.13333333333333,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6514c873829715ded9cd17b1\",\"name\":\"mistralai/Mistral-7B-Instruct-v0.1\",\"display_name\":\"Mistral
        (7B) Instruct\",\"display_type\":\"chat\",\"description\":\"instruct fine-tuned
        version of Mistral-7B-v0.1\",\"license\":\"Apache-2\",\"creator_organization\":\"mistralai\",\"hardware_label\":\"2x
        A100 80GB\",\"num_parameters\":7241732096,\"release_date\":\"2023-09-27T00:00:00.000Z\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":4096,\"config\":{\"add_generation_prompt\":true,\"stop\":[\"[/INST]\",\"</s>\"],\"prompt_format\":\"<s>[INST]
        {prompt} [/INST]\",\"chat_template_name\":\"llama\",\"tools_template\":\"{{
        '<<SYS>>\\\\n' + systemMessage['content'] + '\\\\n\\\\nYou can access the
        following functions. Use them if required -\\\\n' + tools + '\\\\n<</SYS>>\\\\n\\\\n'
        + message['content'] }}\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-09-28T00:27:31.815Z\",\"update_at\":\"2023-10-12T01:13:51.840Z\",\"instances\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\"}],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":13.066666666666666,\"throughput_in\":6693.933333333333,\"throughput_out\":815,\"stats\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\",\"capacity\":0.38378594249201275,\"qps\":13.066666666666666,\"throughput_in\":6693.933333333333,\"throughput_out\":815,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65776c7d6923087ddd5a660a\",\"name\":\"mistralai/Mistral-7B-Instruct-v0.2\",\"display_name\":\"Mistral
        (7B) Instruct v0.2\",\"display_type\":\"chat\",\"description\":\"The Mistral-7B-Instruct-v0.2
        Large Language Model (LLM) is an improved instruct fine-tuned version of Mistral-7B-Instruct-v0.1.\",\"license\":\"apache-2.0\",\"creator_organization\":\"mistralai\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"release_date\":\"2023-11-01T00:00:00.000Z\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"[/INST]\",\"</s>\"],\"chat_template_name\":\"llama\",\"tools_template\":\"{{
        'If you need to invoke any of the following functions:\\n' + tools + '\\nplease
        respond in the following JSON format:\\n[\\n\\n  {\\n    \\\"name\\\": \\\"the
        name of the function to be invoked\\\",\\n    \\\"arguments\\\": {\\\"key1\\\":
        \\\"value1\\\", \\\"key2\\\": \\\"value2\\\", ...}\\n  }\\n]\\nIf any required
        arguments are missing, please ask for them without JSON function calls.\\nIf
        the instruction does not necessitate a function call, please provide your
        response in clear, concise natural language.\\n\\n' + message['content'] }}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-12-11T20:09:33.627Z\",\"update_at\":\"2023-12-11T20:09:33.627Z\",\"instances\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\"}],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.06666666666666667,\"throughput_in\":43,\"throughput_out\":21.8,\"stats\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\",\"capacity\":0.14285714285714285,\"qps\":0.06666666666666667,\"throughput_in\":43,\"throughput_out\":21.8,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6631647fc3b4aab9202b12e0\",\"name\":\"meta-llama/Meta-Llama-3-8B\",\"serviceName\":\"meta-llama/Llama-3-8b-hf\",\"display_name\":\"Meta
        Llama 3 8B\",\"display_type\":\"language\",\"description\":\"Llama 3 is an
        auto-regressive language model that uses an optimized transformer architecture.
        The tuned versions use supervised fine-tuning (SFT) and reinforcement learning
        with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"LLaMA license Agreement (Meta)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3-8B\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"access\":\"open\",\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"owner_userid\":null,\"config\":null,\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-04-18T08:34:37.676Z\",\"update_at\":\"2024-04-18T09:12:37.169Z\",\"instances\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6514c6ee829715ded9cd17b0\",\"name\":\"mistralai/Mistral-7B-v0.1\",\"display_name\":\"Mistral
        (7B)\",\"display_type\":\"language\",\"description\":\"7.3B parameter model
        that outperforms Llama 2 13B on all benchmarks, approaches CodeLlama 7B performance
        on code, Uses Grouped-query attention (GQA) for faster inference and Sliding
        Window Attention (SWA) to handle longer sequences at smaller cost\",\"license\":\"Apache-2\",\"creator_organization\":\"mistralai\",\"hardware_label\":\"2x
        A100 80GB\",\"num_parameters\":7241732096,\"release_date\":\"2023-09-27T00:00:00.000Z\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":\"{prompt}\",\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-09-28T00:21:02.330Z\",\"update_at\":\"2023-09-28T00:21:02.330Z\",\"instances\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\"}],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66636f31028d6a72c2fc8795\",\"name\":\"Qwen/Qwen2-72B-Instruct\",\"display_name\":\"Qwen
        2 Instruct (72B)\",\"display_type\":\"chat\",\"description\":\"Qwen2 is the
        new series of Qwen large language models. For Qwen2, we release a number of
        base language models and instruction-tuned language models ranging from 0.5
        to 72 billion parameters, including a Mixture-of-Experts model.\",\"license\":\"tongyi-qianwen\",\"link\":\"https://huggingface.co/Qwen/Qwen2-72B-Instruct\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":72000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"config\":{\"stop\":[\"<|im_start|>\",\"<|im_end|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] +
        '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n'
        }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-06-07T20:36:01.437Z\",\"instances\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"}],\"isPrivate\":false,\"access_control\":[],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":1.8666666666666667,\"throughput_in\":1581.6,\"throughput_out\":231.39999999999998,\"stats\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.00817392577142282,\"qps\":1.3333333333333333,\"throughput_in\":1063.5333333333333,\"throughput_out\":132.53333333333333,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":0.2545017586022401,\"qps\":0.5333333333333333,\"throughput_in\":518.0666666666667,\"throughput_out\":98.86666666666666,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c85a4975e79f24d98b5a\",\"name\":\"Qwen/Qwen1.5-72B-Chat\",\"display_name\":\"Qwen
        1.5 Chat (72B)\",\"display_type\":\"chat\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"tongyi-qianwen-research\",\"link\":\"https://huggingface.co/Qwen/Qwen1.5-72B-Chat\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":72000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"config\":{\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{%
        if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>'
        + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role']
        != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:58.193Z\",\"update_at\":\"2024-04-17T19:23:06.511Z\",\"instances\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"}],\"isPrivate\":false,\"access_control\":[],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.06666666666666667,\"throughput_in\":18.466666666666665,\"throughput_out\":3.6,\"stats\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0,\"qps\":0.06666666666666667,\"throughput_in\":18.466666666666665,\"throughput_out\":3.6,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"660c58976184ee782ae490f1\",\"name\":\"deepseek-ai/deepseek-llm-67b-chat\",\"display_name\":\"DeepSeek
        LLM Chat (67B)\",\"display_type\":\"chat\",\"description\":\"trained from
        scratch on a vast dataset of 2 trillion tokens in both English and Chinese\",\"license\":\"deepseek\",\"link\":\"https://huggingface.co/deepseek-ai/deepseek-llm-67b-chat\",\"creator_organization\":\"DeepSeek\",\"pricing_tier\":\"\",\"num_parameters\":67000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":4096,\"owner_userid\":\"\",\"config\":{\"prompt_format\":\"\",\"stop\":[\"<\uFF5Cbegin\u2581of\u2581sentence\uFF5C>\",\"<\uFF5Cend\u2581of\u2581sentence\uFF5C>\"],\"bos_token\":\"<\uFF5Cbegin\u2581of\u2581sentence\uFF5C>\",\"add_generation_prompt\":true,\"chat_template\":\"{{
        '<\uFF5Cbegin\u2581of\u2581sentence\uFF5C>' }}{% for message in messages %}{%
        if message['role'] == 'user' %} {{ 'User: ' + message['content'] + '\\n\\n'}}{%
        elif message['role'] == 'assistant' %}{{ 'Assistant: ' + message['content']
        + '<\uFF5Cend\u2581of\u2581sentence\uFF5C>' }}{% endif %}{% endfor %}{% if
        add_generation_prompt %}{{ 'Assistant:' }}{% endif %}\"},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-04-02T19:12:23.328Z\",\"update_at\":\"2024-04-02T19:12:23.328Z\",\"instances\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.13333333333333333,\"throughput_in\":10.133333333333333,\"throughput_out\":19.133333333333333,\"stats\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\",\"capacity\":0.021062271062271064,\"qps\":0.13333333333333333,\"throughput_in\":10.133333333333333,\"throughput_out\":19.133333333333333,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65468604c5ce2e5fa70d6722\",\"name\":\"togethercomputer/m2-bert-80M-8k-retrieval\",\"display_name\":\"M2-BERT-Retrieval-8k\",\"display_type\":\"embedding\",\"description\":\"The
        80M checkpoint for M2-BERT-base from the paper Monarch Mixer: A Simple Sub-Quadratic
        GEMM-Based Architecture with sequence length 8192, and it has been fine-tuned
        for retrieval.\",\"license\":\"apache-2.0\",\"link\":\"https://huggingface.co/togethercomputer/m2-bert-80M-8k-retrieval\",\"creator_organization\":\"Together\",\"hardware_label\":\"L40\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":80000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"context_length\":8192,\"pricing\":{\"hourly\":0,\"input\":2,\"output\":2,\"finetune\":0,\"base\":0},\"created_at\":\"2023-11-04T17:57:24.532Z\",\"update_at\":\"2024-08-30T06:10:17.757Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\"}],\"isPrivate\":false,\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:EMBEDDING_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":1.0666666666666667,\"throughput_in\":841.2,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\",\"capacity\":0.007947198275862068,\"qps\":1.0666666666666667,\"throughput_in\":841.2,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6630011e324b0032b64f35a0\",\"name\":\"togethercomputer/Llama-3-8b-chat-hf-int8\",\"display_name\":\"Togethercomputer
        Llama3 8B Instruct Int8\",\"display_type\":\"chat\",\"description\":\"Llama
        3 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"owner_userid\":null,\"parent\":\"meta-llama/Llama-3-8b-chat-hf\",\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-04-18T06:07:59.041Z\",\"update_at\":\"2024-04-24T19:14:26.075Z\",\"instances\":[{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"}],\"isPrivate\":true,\"access_control\":[],\"isDedicatedInstance\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"664e47f5b4be29d59d4e7f70\",\"name\":\"mistralai/Mistral-7B-Instruct-v0.3\",\"display_name\":\"Mistral
        (7B) Instruct v0.3\",\"display_type\":\"chat\",\"description\":\"The Mistral-7B-Instruct-v0.3
        Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.3.\",\"license\":\"apache-2.0\",\"link\":\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\",\"creator_organization\":\"mistralai\",\"num_parameters\":7000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"context_length\":32768,\"owner_userid\":null,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\",\"bos_token\":\"<s>\",\"eos_token\":\"</s>\"},\"pricing\":{\"hourly\":0,\"input\":50,\"output\":50},\"created_at\":\"2024-05-22T19:31:01.920Z\",\"update_at\":\"2024-08-30T05:45:45.158Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":5,\"throughput_in\":4537.866666666667,\"throughput_out\":1302.1333333333334,\"stats\":[{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0.9520502645502645,\"qps\":5,\"throughput_in\":4537.866666666667,\"throughput_out\":1302.1333333333334,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"663929111a16009453d858d6\",\"name\":\"Qwen/Qwen1.5-110B-Chat\",\"display_name\":\"Qwen
        1.5 Chat (110B)\",\"display_type\":\"chat\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"tongyi-qianwen-research\",\"link\":\"https://huggingface.co/Qwen/Qwen1.5-110B-Chat\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":110000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"owner_userid\":null,\"config\":{\"stop\":[\"<|im_end|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] +
        '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n'
        }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":450,\"output\":450,\"hourly\":0},\"created_at\":\"2024-05-06T19:01:37.206Z\",\"update_at\":\"2024-05-06T19:01:37.206Z\",\"instances\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.2,\"throughput_in\":161.79999999999998,\"throughput_out\":45.46666666666667,\"stats\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0,\"qps\":0.06666666666666667,\"throughput_in\":46.93333333333333,\"throughput_out\":5.466666666666667,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0,\"qps\":0.13333333333333333,\"throughput_in\":114.86666666666666,\"throughput_out\":40,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6dd9de620478cfa144258\",\"name\":\"meta-llama/Llama-2-13b-chat-hf\",\"display_name\":\"LLaMA-2
        Chat (13B)\",\"display_type\":\"chat\",\"description\":\"Llama 2-chat leverages
        publicly available instruction datasets and over 1 million human annotations.
        Available in three sizes: 7B, 13B and 70B parameters\",\"license\":\"LLaMA
        license Agreement (Meta)\",\"link\":\"https://huggingface.co/meta-llama/Llama-2-13b-chat-hf\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":13015864320,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":4096,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"[/INST]\",\"</s>\"],\"add_generation_prompt\":true,\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":55,\"output\":55,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-12-04T05:00:54.436Z\",\"instances\":[{\"avzone\":\"us-west-1a\",\"cluster\":\"curiouscrow\"}],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.06666666666666667,\"throughput_in\":40.93333333333333,\"throughput_out\":3.3333333333333335,\"stats\":[{\"avzone\":\"us-west-1a\",\"cluster\":\"curiouscrow\",\"capacity\":0.09999999999999999,\"qps\":0.06666666666666667,\"throughput_in\":40.93333333333333,\"throughput_out\":3.3333333333333335,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6695818dc6077eef0b287091\",\"name\":\"google/gemma-2-27b-it\",\"display_name\":\"Gemma-2
        Instruct (27B)\",\"display_type\":\"chat\",\"description\":\"Gemma is a family
        of lightweight, state-of-the-art open models from Google, built from the same
        research and technology used to create the Gemini models.\",\"license\":\"gemma-terms-of-use\",\"link\":\"https://huggingface.co/google/gemma-2b-it\",\"creator_organization\":\"Google\",\"pricing_tier\":\"Featured\",\"num_parameters\":2000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"context_length\":8192,\"config\":{\"stop\":[\"<eos>\",\"<end_of_turn>\"],\"chat_template\":\"{{
        bos_token }}{% for message in messages %}{% if (message['role'] == 'assistant')
        %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif
        %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n'
        }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{%
        endif %}\",\"bos_token\":\"<bos>\",\"eos_token\":\"<end_of_turn>\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":200,\"output\":200},\"created_at\":\"2024-02-23T00:36:46.381Z\",\"update_at\":\"2024-09-09T03:34:22.892Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.8666666666666667,\"throughput_in\":972.2666666666667,\"throughput_out\":116.73333333333333,\"stats\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.04364326375711574,\"qps\":0.3333333333333333,\"throughput_in\":471.4,\"throughput_out\":55.13333333333333,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0.03637611530542208,\"qps\":0.5333333333333333,\"throughput_in\":500.8666666666667,\"throughput_out\":61.6,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669856df5130711899d044f5\",\"name\":\"meta-llama/Meta-Llama-3-70B-Instruct-Turbo\",\"display_name\":\"Meta
        Llama 3 70B Instruct Turbo\",\"display_type\":\"chat\",\"description\":\"Llama
        3 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"context_length\":8192,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":220,\"output\":220},\"instances\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:turbo,category:LLAMA3\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":3.1333333333333333,\"throughput_in\":6438.866666666667,\"throughput_out\":306,\"stats\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.0929054054054054,\"qps\":2,\"throughput_in\":3837.3333333333335,\"throughput_out\":196.33333333333334,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.07835820895522388,\"qps\":1.1333333333333333,\"throughput_in\":2601.5333333333333,\"throughput_out\":109.66666666666667,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6698676d7462038dbadb4365\",\"name\":\"meta-llama/Meta-Llama-3-70B-Instruct-Lite\",\"display_name\":\"Meta
        Llama 3 70B Instruct Lite\",\"display_type\":\"chat\",\"description\":\"Llama
        3 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":8192,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":135,\"output\":135},\"instances\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\"},{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:lite,category:LLAMA3\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.33333333333333337,\"throughput_in\":637.5999999999999,\"throughput_out\":45.06666666666666,\"stats\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\",\"capacity\":0.14285714285714282,\"qps\":0.13333333333333333,\"throughput_in\":267.3333333333333,\"throughput_out\":21.8,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\",\"capacity\":0.14285714285714282,\"qps\":0.2,\"throughput_in\":370.26666666666665,\"throughput_out\":23.266666666666666,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6696b4ee04b09125de687ed5\",\"name\":\"google/gemma-2-9b-it\",\"display_name\":\"Gemma-2
        Instruct (9B)\",\"display_type\":\"chat\",\"description\":\"Gemma is a family
        of lightweight, state-of-the-art open models from Google, built from the same
        research and technology used to create the Gemini models.\",\"license\":\"gemma\",\"link\":\"https://huggingface.co/google/gemma-2-9b-it\",\"creator_organization\":\"google\",\"pricing_tier\":\"Featured\",\"num_parameters\":9000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":8192,\"config\":{\"stop\":[\"<end_of_turn>\",\"<eos>\"],\"chat_template_name\":\"\",\"chat_template\":\"{{
        bos_token }}{% for message in messages %}{% if (message['role'] == 'assistant')
        %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif
        %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n'
        }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{%
        endif %}\",\"bos_token\":\"<bos>\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":75,\"output\":75},\"created_at\":\"2024-02-23T00:36:46.381Z\",\"update_at\":\"2024-07-16T21:02:25.393Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.7333333333333333,\"throughput_in\":884.4,\"throughput_out\":51.6,\"stats\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.06385869565217392,\"qps\":0.7333333333333333,\"throughput_in\":884.4,\"throughput_out\":51.6,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669838f1c8a631c059aba520\",\"name\":\"google/gemma-2-9b\",\"display_name\":\"Gemma
        2 (9B)\",\"display_type\":\"language\",\"description\":\"Gemma is a family
        of lightweight, state-of-the-art open models from Google, built from the same
        research and technology used to create the Gemini models.\",\"license\":\"gemma\",\"link\":\"https://huggingface.co/google/gemma-2-9b\",\"creator_organization\":\"google\",\"pricing_tier\":\"Featured\",\"num_parameters\":9000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0},\"created_at\":\"2024-02-23T00:36:46.381Z\",\"update_at\":\"2024-07-16T21:02:25.393Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"status\":\"cancelled\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":true,\"isSelfServeDedicatedInstance\":true,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"undefined\",\"cluster\":\"undefined\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6620b8bf4b2da307838b7cf0\",\"name\":\"meta-llama/Llama-3-8b-chat-hf\",\"display_name\":\"Meta
        Llama 3 8B Instruct Reference\",\"display_type\":\"chat\",\"description\":\"Llama
        3 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":8192,\"owner_userid\":null,\"parent\":\"meta-llama/Llama-3-8b-chat-hf\",\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":50,\"output\":50},\"created_at\":\"2024-04-18T06:07:59.041Z\",\"update_at\":\"2024-06-08T04:33:50.412Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.3333333333333333,\"throughput_in\":436.5333333333333,\"throughput_out\":22.8,\"stats\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.0625,\"qps\":0.13333333333333333,\"throughput_in\":168.93333333333334,\"throughput_out\":6.2,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":0.06944444444444445,\"qps\":0.13333333333333333,\"throughput_in\":203.73333333333332,\"throughput_out\":14,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.078125,\"qps\":0.06666666666666667,\"throughput_in\":63.86666666666667,\"throughput_out\":2.6,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"661d747e2bfa86bd832690c1\",\"name\":\"microsoft/WizardLM-2-8x22B\",\"display_name\":\"WizardLM-2
        (8x22B)\",\"display_type\":\"chat\",\"description\":\"WizardLM-2 8x22B is
        Wizard's most advanced model, demonstrates highly competitive performance
        compared to those leading proprietary works and consistently outperforms all
        the existing state-of-the-art opensource models.\",\"license\":\"apache-2.0\",\"link\":\"https://huggingface.co/microsoft/WizardLM-2-8x22B\",\"creator_organization\":\"microsoft\",\"pricing_tier\":\"Featured\",\"num_parameters\":141000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"context_length\":65536,\"owner_userid\":null,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":null,\"chat_template\":\"{%
        for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content']
        + '\\n'}}{% endfor %}{{ 'ASSISTANT: ' }}\",\"add_generation_prompt\":true,\"bos_token\":\"<s>\",\"eos_token\":\"</s>\"},\"pricing\":{\"hourly\":0,\"input\":300,\"output\":300},\"created_at\":\"2024-04-15T18:39:58.959Z\",\"update_at\":\"2024-08-30T05:41:05.730Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isByom\":false,\"engine\":\"vllm\",\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.4,\"throughput_in\":147.6,\"throughput_out\":180.33333333333334,\"stats\":[{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0.4921052631578949,\"qps\":0.4,\"throughput_in\":147.6,\"throughput_out\":180.33333333333334,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6577af4434e6c1e2bb5283d8\",\"name\":\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\"display_name\":\"Mixtral-8x7B
        Instruct v0.1\",\"display_type\":\"chat\",\"description\":\"The Mixtral-8x7B
        Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.\",\"license\":\"apache-2.0\",\"link\":\"https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1\",\"creator_organization\":\"mistralai\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":56000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"[/INST]\",\"</s>\"],\"chat_template_name\":\"llama\",\"tools_template\":\"{{
        '<<SYS>>\\\\n' + systemMessage['content'] + '\\\\n\\\\nYou can access the
        following functions. Use them if required -\\\\n' + tools + '\\\\n<</SYS>>\\\\n\\\\n'
        + message['content'] }}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":150,\"output\":150,\"hourly\":0},\"created_at\":\"2023-12-12T00:54:28.108Z\",\"update_at\":\"2024-02-08T07:58:24.624Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"instances\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"}],\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":3.6,\"throughput_in\":6827.666666666666,\"throughput_out\":846.9333333333334,\"stats\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.1078547895988957,\"qps\":2.3333333333333335,\"throughput_in\":4420.333333333333,\"throughput_out\":590.0666666666667,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.09284351873044934,\"qps\":0.6,\"throughput_in\":1033.2666666666667,\"throughput_out\":100.53333333333333,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":0.05743026333550483,\"qps\":0.6666666666666666,\"throughput_in\":1374.0666666666666,\"throughput_out\":156.33333333333334,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6620daf44b2da307838b7cf1\",\"name\":\"meta-llama/Llama-3-70b-chat-hf\",\"display_name\":\"Meta
        Llama 3 70B Instruct Reference\",\"display_type\":\"chat\",\"description\":\"Llama
        3 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"num_parameters\":70000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":8192,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":225,\"output\":225},\"created_at\":\"2024-04-18T08:33:56.492Z\",\"update_at\":\"2024-06-28T00:10:47.255Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"instances\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"},{\"avzone\":\"ca-east-1a\",\"cluster\":\"poutinepenguin\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":9.466666666666667,\"throughput_in\":10209.400000000001,\"throughput_out\":1087.2666666666667,\"stats\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.13271604938271606,\"qps\":1.2,\"throughput_in\":1106.5333333333333,\"throughput_out\":142.93333333333334,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.09859913793103449,\"qps\":1.3333333333333333,\"throughput_in\":1105.4,\"throughput_out\":120.66666666666667,\"error_rate\":0.06666666666666667,\"retry_rate\":0},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":0.09706221198156682,\"qps\":4.2,\"throughput_in\":4485.533333333334,\"throughput_out\":421.46666666666664,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"ca-east-1a\",\"cluster\":\"poutinepenguin\",\"capacity\":0.09311224489795919,\"qps\":2.7333333333333334,\"throughput_in\":3511.9333333333334,\"throughput_out\":402.2,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0.06666666666666667,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66be43e6569f797901140859\",\"name\":\"Salesforce/Llama-Rank-V1\",\"display_name\":\"Salesforce
        Llama Rank V1 (8B)\",\"display_type\":\"rerank\",\"description\":\"LlamaRank
        is a language model specialized for document ranking. LlamaRank achieves performance
        at least comparable to leading APIs across general document ranking while
        demonstrating a marked improvement in code search.\",\"license\":\"llama3\",\"link\":\"\",\"creator_organization\":\"salesforce\",\"num_parameters\":8000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":8192,\"owner_userid\":\"\",\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt
        %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\nAfter carefully reading
        the query, document, and guidelines, I have determined that the relevance
        score is: ' }}{% endif %}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|eot_id|>\",\"add_generation_prompt\":true,\"template\":\"You
        will be given a QUERY and a DOCUMENT and you must determine if the QUERY is
        RELEVANT to the DOCUMENT under certain guidelines.\\n\\nQUERY: {{ query }}\\n\\n\\nDOCUMENT:\\n{{
        document }}\\n\\n\\nHere are the guidelines and additional instructions:\\n\\nRELEVANCE
        SCORING RUBRIC:\\nYou will give a score between 1 and 5, where 1 is NOT RELEVANT
        and 5 is PERFECTLY RELEVANT.\\nHere are more details on the scoring rubric:\\n1.
        1: NOT RELEVANT - The document is not relevant to the query. It seems like
        it could have been selected at random from the hypothetical set of all possible
        documents.\\n2. 2: MARGINALLY RELEVANT - The document is marginally relevant
        to the query, so it seems somewhat or loosely more related than a totally
        random article. However, it is not very helpful and does not contain information
        that is directly pertient to the query.\\n3. 3: SOMEWHAT RELEVANT - The document
        is somewhat relevant to the query. It may contain information from which an
        answer might be interpreted or extrapolated, or at least information which
        might be considered helpful for the query even if it does not directly answer
        it. It does not directly match the query.\\n4. 4: RELEVANT - The document
        is relevant to the query. It contains information that is mostly related to
        the query and could be considered helpful in answering the query. It contains
        a solid answer to the query or reasonable coverage of the topic.\\n5. 5: PERFECTLY
        RELEVANT - The document is perfectly relevant to the query. It contains information
        that is directly related to the query and provides a clear and concise answer
        to the query. It is (almost) the best possible document that could be selected
        for the query from the hypothetical set of all documents.\\n\",\"weighted_tokens\":[{\"token\":\"1\",\"weight\":0},{\"token\":\"2\",\"weight\":0.24},{\"token\":\"3\",\"weight\":0.63},{\"token\":\"4\",\"weight\":0.8},{\"token\":\"5\",\"weight\":1}],\"max_documents\":1024},\"pricing\":{\"input\":25,\"output\":0,\"hourly\":0},\"created_at\":\"2024-08-15T18:07:34.337Z\",\"update_at\":\"2024-08-15T18:07:34.337Z\",\"instances\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"engine\":\"vllm\",\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"661456e0c60f613bee9d2d06\",\"name\":\"databricks/dbrx-instruct\",\"display_name\":\"DBRX
        Instruct\",\"display_type\":\"chat\",\"description\":\"DBRX Instruct is a
        mixture-of-experts (MoE) large language model trained from scratch by Databricks.
        DBRX Instruct specializes in few-turn interactions.\",\"license\":\"Databricks
        Open Model License\",\"link\":\"https://huggingface.co/databricks/dbrx-instruct\",\"creator_organization\":\"Databricks\",\"hardware_label\":\"4X
        H100 80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":132000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"config\":{\"add_generation_prompt\":true,\"chat_template_name\":\"default\",\"stop\":[\"<|im_start|>\",\"<|im_end|>\"]},\"pricing\":{\"input\":300,\"output\":300,\"hourly\":0},\"instances\":[{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"}],\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.2,\"throughput_in\":80.13333333333334,\"throughput_out\":8.2,\"stats\":[{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":2.8125,\"qps\":0.2,\"throughput_in\":80.13333333333334,\"throughput_out\":8.2,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a4b298fbc8405400423169\",\"name\":\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\",\"display_name\":\"Nous
        Hermes 2 - Mixtral 8x7B-DPO \",\"display_type\":\"chat\",\"description\":\"Nous
        Hermes 2 Mixtral 7bx8 DPO is the new flagship Nous Research model trained
        over the Mixtral 7bx8 MoE LLM. The model was trained on over 1,000,000 entries
        of primarily GPT-4 generated data, as well as other high quality data from
        open datasets across the AI landscape, achieving state of the art performance
        on a variety of tasks.\",\"license\":\"apache-2.0\",\"link\":\"https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\",\"creator_organization\":\"NousResearch\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":56000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"config\":{\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"add_generation_prompt\":true,\"chat_template_name\":\"default\"},\"pricing\":{\"hourly\":0,\"input\":150,\"output\":150},\"created_at\":\"2024-01-15T04:20:40.079Z\",\"update_at\":\"2024-08-30T04:41:19.577Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"}],\"isPrivate\":false,\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.2,\"throughput_in\":369,\"throughput_out\":37.2,\"stats\":[{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0.075,\"qps\":0.2,\"throughput_in\":369,\"throughput_out\":37.2,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66985d6b7462038dbadb4363\",\"name\":\"meta-llama/Meta-Llama-3-8B-Instruct-Turbo\",\"display_name\":\"Meta
        Llama 3 8B Instruct Turbo\",\"display_type\":\"chat\",\"description\":\"Llama
        3 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"num_parameters\":8000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":8192,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":45,\"output\":45},\"instances\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:turbo,category:LLAMA3\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.3333333333333333,\"throughput_in\":144.2,\"throughput_out\":13.733333333333333,\"stats\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.0625,\"qps\":0.3333333333333333,\"throughput_in\":144.2,\"throughput_out\":13.733333333333333,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.0625,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6dd0ee620478cfa144256\",\"name\":\"meta-llama/Llama-2-70b-hf\",\"display_name\":\"LLaMA-2
        (70B)\",\"display_type\":\"language\",\"description\":\"Language model trained
        on 2 trillion tokens with double the context length of Llama 1. Available
        in three sizes: 7B, 13B and 70B parameters\",\"license\":\"LLaMA license Agreement
        (Meta)\",\"link\":\"https://huggingface.co/meta-llama/Llama-2-70b-hf\",\"creator_organization\":\"Meta\",\"hardware_label\":\"2X
        A100 80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":68976648192,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\"]},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-07-18T22:46:55.042Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"instances\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\"}],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":45.06666666666667,\"throughput_in\":2383.733333333333,\"throughput_out\":280.06666666666666,\"stats\":[{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\",\"capacity\":0.5040769000598444,\"qps\":45.06666666666667,\"throughput_in\":2383.733333333333,\"throughput_out\":280.06666666666666,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669867007462038dbadb4364\",\"name\":\"meta-llama/Meta-Llama-3-8B-Instruct-Lite\",\"display_name\":\"Meta
        Llama 3 8B Instruct Lite\",\"display_type\":\"chat\",\"description\":\"Llama
        3 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"num_parameters\":8000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":8192,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":25,\"output\":25},\"instances\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:lite,category:LLAMA3\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\",\"capacity\":0.14285714285714285,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6573540efe9a5c79871809ce\",\"name\":\"Meta-Llama/Llama-Guard-7b\",\"display_name\":\"Llama
        Guard (7B)\",\"display_type\":\"moderation\",\"description\":\"Llama Guard:
        LLM-based Input-Output Safeguard for Human-AI Conversations\",\"license\":\"LLaMA
        license Agreement (Meta)\",\"link\":\"https://huggingface.co/meta-llama/LlamaGuard-7b\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":4096,\"config\":{\"chat_template\":\"{{
        '[INST] Task: Check if there is unsafe content in \\\\'' }}{% if messages[messages.length-1]['role']
        == 'user' %}{{ 'User' }}{% else %}{{ 'Agent' }}{% endif %}{{ '\\\\' messages
        in conversations according our safety policy with the below categories.\\n\\n<BEGIN
        UNSAFE CONTENT CATEGORIES>\\nO1: Violence and Hate. \\nShould not\\n - Help
        people plan or engage in violence.\\n - Encourage people to engage in violence.\\n
        - Express hateful, derogatory, or demeaning sentiments against people based
        on sensitive personal characteristics like their race, color, religion, national
        origin, sexual orientation, gender, gender identity, or disability.\\n - Encourage
        discrimination against people based on those characteristics and should not
        use slurs or create insults based on those characteristics.\\nCan\\n - Provide
        information on violence and discrimination.\\n - Discuss the topics of hate
        and violence, and can discuss historical events involving violence.\\nO2:
        Sexual Content. \\nShould not\\n - Engage in sexually explicit (i.e., erotic)
        conversations and should not encourage people to engage in sexual activities.\\nCan\\n
        - Discuss topics related to sexuality and sexual education.\\n - Provide general
        information regarding sexual activities.\\n - Provide guidance on topics related
        to sexual health.\\nO3: Criminal Planning. \\nShould not\\n - Help people
        plan or engage in criminal activities like theft, kidnapping, or financial
        crimes, especially when the person indicates that they may act on the information
        provided to them.\\n - Encourage people to engage in criminal activities or
        condone criminal behavior.\\nCan\\n - Help people understand how crimes are
        committed, provided that the response is not so detailed that it could be
        used to provide a roadmap for future crimes.\\n - Help people understand how
        systems work that are used to prevent crimes, provided those descriptions
        do not provide detailed information on how to defeat those systems.\\nO4:
        Guns and Illegal Weapons. \\nShould not\\n - Assist in the planning or execution
        of firearm or illegal weapons crimes, especially when the person indicates
        that they may act on the information provided to them.\\n - Encourage people
        to engage in firearm or illegal weapons crimes or condone such behavior.\\nCan\\n
        - Discuss firearms and the arguments for and against firearm ownership.\\nO5:
        Regulated or Controlled Substances. \\nShould not\\n - Encourage or assist
        people in the trafficking, consumption, or use of regulated or controlled
        substances, including but not limited to illegal drugs, tobacco, alcohol,
        and cannabis.\\n - Assist or encourage people to create such substances when
        it is illegal to do so.\\nCan\\n - Discuss the use of regulated or controlled
        substances, and can provide general information on those substances (ex: what
        their chemical composition is and what their effects are).\\n - Provide information
        on how those substances are manufactured, provided that the information is
        not so detailed as to provide step-by-step instructions for their creation.\\nO6:
        Self-Harm. \\nShould not\\n - Encourage people to harm themselves.\\n - Romanticize
        or condone self-harm or suicide.\\n - Provide information regarding the methods
        of suicide or self-harm.\\n - Provide any information or advice, other than
        information regarding appropriate health resources, to people who express
        or imply that they wish to harm themselves.\\nCan\\n - Provide general information
        regarding self-harm and suicide (ex: statistics, the mental health challenges
        faced by those who take these actions).\\nShould\\n - Provide information
        regarding appropriate health resources to people who imply or express the
        desire to harm themselves.\\n<END UNSAFE CONTENT CATEGORIES>\\n\\n<BEGIN CONVERSATION>\\n\\n'
        }}{% for message in messages %}{% if message['role'] == 'user' %}{{ 'User:
        ' + message['content'] + '\\n\\n' }}{% else %}{{ 'Agent: ' + message['content']
        + '\\n\\n' }}{% endif %}{% endfor %}{{ '<END CONVERSATION>\\n\\nProvide your
        safety assessment for '}}{% if messages[messages.length-1]['role'] == 'user'
        %}{{ 'User' }}{% else %}{{ 'Agent' }}{% endif %}{{' in the above conversation:\\n
        - First line must read \\\\'safe\\\\' or \\\\'unsafe\\\\'.\\n - If unsafe,
        a second line must include a comma-separated list of violated categories.
        [/INST]' }}\",\"safety_label\":\"safe\",\"safe_response\":true,\"safety_config\":{\"max_tokens\":64},\"safety_categories\":{\"O1\":\"Violence
        and Hate\",\"O2\":\"Sexual Content\",\"O3\":\"Criminal Planning\",\"O4\":\"Guns
        and Illegal Weapons\",\"O5\":\"Regulated or Controlled Substances\",\"O6\":\"Self-Harm\"}},\"pricing\":{\"hourly\":0,\"input\":50,\"output\":50},\"update_at\":\"2024-04-20T23:25:17.775Z\",\"instances\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\"},{\"avzone\":\"ap-northeast-1a\",\"cluster\":\"optimisticotter\"},{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\"}],\"lago_tag\":\"metricTag:LLAMA_GUARD\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":17.933333333333334,\"throughput_in\":16960.6,\"throughput_out\":38.06666666666667,\"stats\":[{\"avzone\":\"us-central-5a\",\"cluster\":\"wrigleycub\",\"capacity\":0.07852112676056344,\"qps\":9.133333333333333,\"throughput_in\":8418.666666666666,\"throughput_out\":19.666666666666668,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"ap-northeast-1a\",\"cluster\":\"optimisticotter\",\"capacity\":0.06672932330827093,\"qps\":3.6666666666666665,\"throughput_in\":3683.4,\"throughput_out\":7.533333333333333,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-east-2a\",\"cluster\":\"jumpyjackal\",\"capacity\":0.08228571428571409,\"qps\":5.133333333333334,\"throughput_in\":4858.533333333334,\"throughput_out\":10.866666666666667,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669dbe272eb8e5106449046a\",\"name\":\"meta-llama/Meta-Llama-3.1-8B-Instruct-Reference\",\"display_name\":\"Meta
        Llama 3.1 8B Instruct\",\"display_type\":\"chat\",\"description\":\"Llama
        3.1 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3.1 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|eot_id|>\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-07-21T23:06:47.792Z\",\"update_at\":\"2024-07-21T23:06:47.792Z\",\"instances\":[{\"status\":\"cancelled\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":true,\"isSelfServeDedicatedInstance\":true,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:reference,category:LLAMA3\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"undefined\",\"cluster\":\"undefined\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6620059786c156450dc1e445\",\"name\":\"mistralai/Mixtral-8x22B-Instruct-v0.1\",\"display_name\":\"Mixtral-8x22B
        Instruct v0.1\",\"display_type\":\"chat\",\"description\":\"The Mixtral-8x22B-Instruct-v0.1
        Large Language Model (LLM) is an instruct fine-tuned version of the Mixtral-8x22B-v0.1.\",\"license\":\"apache-2.0\",\"link\":\"https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1\",\"creator_organization\":\"mistralai\",\"pricing_tier\":\"Featured\",\"num_parameters\":141000000000,\"show_in_playground\":true,\"isFeaturedModel\":true,\"context_length\":65536,\"owner_userid\":null,\"config\":{\"stop\":[\"</s>\",\"[/INST]\"],\"chat_template\":\"{{bos_token}}{%
        if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{%
        set system_message = messages[0]['content'] %}{% else %}{% set loop_messages
        = messages %}{% set system_message = false %}{% endif %}{% for message in
        loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set
        content = '<<SYS>>\\n' + system_message + '\\n<</SYS>>\\n\\n' + message['content']
        %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role']
        == 'user' %}{{ ' [INST] ' + content + ' [/INST]' }}{% elif message['role']
        == 'system' %}{{ '<<SYS>>\\n' + content + '\\n<</SYS>>\\n\\n' }}{% elif message['role']
        == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor
        %}\",\"bos_token\":\"<s>\",\"eos_token\":\"</s>\"},\"pricing\":{\"input\":300,\"output\":300,\"hourly\":0},\"created_at\":\"2024-04-17T17:23:35.226Z\",\"update_at\":\"2024-05-03T01:20:25.932Z\",\"instances\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":6.066666666666666,\"throughput_in\":53122.93333333333,\"throughput_out\":495.8666666666667,\"stats\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.39002312986932064,\"qps\":2.2,\"throughput_in\":20194.333333333332,\"throughput_out\":136.13333333333333,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0.6941701075839689,\"qps\":1.4666666666666666,\"throughput_in\":12942.4,\"throughput_out\":99,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.5094149697825778,\"qps\":1.4,\"throughput_in\":11924.8,\"throughput_out\":142.73333333333332,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":0.2500009536779544,\"qps\":1,\"throughput_in\":8061.4,\"throughput_out\":118,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669d96632eb8e51064490468\",\"name\":\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\"display_name\":\"Meta
        Llama 3.1 70B Instruct Turbo\",\"display_type\":\"chat\",\"description\":\"Llama
        3.1 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3.1 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":70000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\",\"<|eom_id|>\"],\"constraintVariants\":[{\"type\":\"json_schema\",\"model_name\":\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo-vLLM\"},{\"type\":\"tools\",\"model_name\":\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\"}],\"contextLengthVariants\":[{\"min_context\":8192,\"model_name\":\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo-vLLM\"}],\"chat_template\":\"{{-
        bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools
        %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%-
        set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string
        is defined %}\\n    {%- set date_string = \\\"26 Jul 2024\\\" %}\\n{%- endif
        %}\\n\\n{#- This block extracts the system message, so we can slot it into
        the right place. #}\\n{%- if messages[0]['role'] == 'system' %}\\n    {%-
        set system_message = messages[0]['content']|trim %}\\n    {%- set messages
        = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \\\"\\\" %}\\n{%-
        endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \\\"<|start_header_id|>system<|end_header_id|>\\n\\n\\\"
        }}\\n{%- if builtin_tools is defined or tools %}\\n    {{- \\\"Environment:
        ipython\\n\\\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{-
        \\\"Tools: \\\" + builtin_tools | reject('equalto', 'code_interpreter') |
        join(\\\", \\\") + \\\"\\n\\n\\\"}}\\n{%- endif %}\\n{{- \\\"Cutting Knowledge
        Date: December 2023\\n\\\" }}\\n{{- \\\"Today Date: \\\" + date_string + \\\"\\n\\n\\\"
        }}\\n{%- if tools %}\\n    {{- \\\"You have access to the following functions:\\n\\n\\\"
        }}{%- for t in tools %}\\n        {{- \\\"Use the function '\\\" + t.function.name
        + \\\"' to '\\\" + t.function.description + \\\"'\\n\\\" }}\\n        {{-
        t.function | dump(4) }}\\n        {{- \\\"\\n\\n\\\" }}\\n    {%- endfor %}\\n{%
        raw %}If a you choose to call a function ONLY reply in the following format:\\n<{start_tag}={function_name}>{parameters}{end_tag}\\nwhere\\n\\nstart_tag
        => `<function`\\nparameters => a JSON dict with the function argument name
        as key and function argument value as value.\\nend_tag => `</function>`\\n\\nHere
        is an example,\\n<function=example_function_name>{\\\"example_name\\\": \\\"example_value\\\"}</function>\\n\\nReminder:\\n-
        Function calls MUST follow the specified format\\n- Required parameters MUST
        be specified\\n- Only call one function at a time\\n- Put the entire function
        call reply on one line\\n- Always add your sources when using search results
        to answer the user query\\n\\n{% endraw %}{%- endif %}\\n{{- system_message
        }}\\n{{- \\\"<|eot_id|>\\\" }}\\n\\n{%- for message in messages %}\\n    {%-
        if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls'
        in message) %}\\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+
        message['content'] | trim + '<|eot_id|>' }}\\n    {%- elif 'tool_calls' in
        message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{-
        raise_exception(\\\"This model only supports single tool-calls at once!\\\")
        }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function
        %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools
        %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        -}}\\n            {{- \\\"<|python_tag|>\\\" + tool_call.name + \\\".call(\\\"
        }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items
        %}\\n                {{- arg_name + '=\\\"' + arg_val + '\\\"' }}\\n                {%-
        if not loop.last %}\\n                    {{- \\\", \\\" }}\\n                {%-
        endif %}\\n                {%- endfor %}\\n            {{- \\\")\\\" }}\\n
        \       {%- else  %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        -}}\\n            {{- '{\\\"name\\\": \\\"' + tool_call.name + '\\\", ' }}\\n
        \           {{- '\\\"parameters\\\": ' }}\\n            {{- tool_call.arguments
        | dump }}\\n            {{- \\\"}\\\" }}\\n        {%- endif %}\\n        {%-
        if builtin_tools is defined %}\\n            {#- This means we're in ipython
        mode #}\\n            {{- \\\"<|eom_id|>\\\" }}\\n        {%- else %}\\n            {{-
        \\\"<|eot_id|>\\\" }}\\n        {%- endif %}\\n    {%- elif message.role ==
        \\\"tool\\\" or message.role == \\\"ipython\\\" %}\\n        {{- \\\"<|start_header_id|>ipython<|end_header_id|>\\n\\n\\\"
        }}\\n        {%- if message.content is mapping or message.content is iterable
        %}\\n            {{- message.content | dump }}\\n        {%- else %}\\n            {{-
        message.content }}\\n        {%- endif %}\\n        {{- \\\"<|eot_id|>\\\"
        }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n
        \   {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{%- endif
        %}\",\"tool_type\":\"llama3.1\",\"force_template\":true,\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|eot_id|>\",\"add_generation_prompt\":true,\"max_tokens\":2048},\"pricing\":{\"hourly\":0,\"input\":220,\"output\":220},\"created_at\":\"2024-07-21T23:14:43.753Z\",\"update_at\":\"2024-09-06T09:20:29.554Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"ca-east-1a\",\"cluster\":\"poutinepenguin\"},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"}],\"isPrivate\":false,\"access_control\":[{\"user_id\":\"65776b1c6943bff034b2248f\",\"role\":\"admin\"},{\"user_id\":\"63b8c450fc5f8b00a9eb88be\",\"role\":\"admin\"},{\"user_id\":\"65503d59c4e8d25c07854c0b\",\"role\":\"admin\"},{\"user_id\":\"63b46d7f108537a03cf0e2a4\",\"role\":\"admin\"},{\"user_id\":\"665e248837cb8a07b7dbd3cc\",\"role\":\"admin\"},{\"user_id\":\"66956c01ebc8ecf40784ec6a\",\"role\":\"admin\"},{\"user_id\":\"6684202b9a9836ec1f2ef970\",\"role\":\"admin\"},{\"user_id\":\"65e640b01a72659c1bede3d6\",\"role\":\"admin\"},{\"user_id\":\"64b58e15d947d0a7b785410a\",\"role\":\"admin\"},{\"user_id\":\"65d4fffb5bd967690b522117\",\"role\":\"admin\"},{\"user_id\":\"64ca98ed0f09c5c91516b39b\",\"role\":\"admin\"}],\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:turbo,category:LLAMA3\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":32.2,\"throughput_in\":48892.00000000001,\"throughput_out\":10576.4,\"stats\":[{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.3404497589966185,\"qps\":2.4,\"throughput_in\":3299.5333333333333,\"throughput_out\":847.0666666666667,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"ca-east-1a\",\"cluster\":\"poutinepenguin\",\"capacity\":0.3915781650148904,\"qps\":4.933333333333334,\"throughput_in\":8274.066666666668,\"throughput_out\":1786,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0.3858659230663888,\"qps\":10.266666666666667,\"throughput_in\":16299.2,\"throughput_out\":3398.2,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":0.45581900176966983,\"qps\":12.133333333333333,\"throughput_in\":18224.866666666665,\"throughput_out\":3935,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.2609712722493916,\"qps\":2.466666666666667,\"throughput_in\":2794.3333333333335,\"throughput_out\":610.1333333333333,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66d2a296929e90dca8aad604\",\"name\":\"Gryphe/MythoMax-L2-13b-Lite\",\"display_name\":\"Gryphe
        MythoMax L2 Lite (13B)\",\"display_type\":\"chat\",\"description\":\"MythoLogic-L2
        and Huginn merge using a highly experimental tensor type merge technique.
        The main difference with MythoMix is that I allowed more of Huginn to intermingle
        with the single tensors located at the front and end of a model\",\"license\":\"other\",\"creator_organization\":\"Gryphe\",\"hardware_label\":\"1x
        A100 80GB\",\"num_parameters\":13000000000,\"release_date\":\"2023-08-01T00:00:00.000Z\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"context_length\":4096,\"owner_userid\":null,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n### Response:\",\"add_generation_prompt\":true,\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n'
        + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\",\"track_qps\":true},\"pricing\":{\"hourly\":0,\"input\":50,\"output\":100},\"created_at\":\"2023-09-05T19:58:25.683Z\",\"update_at\":\"2024-09-03T22:59:46.402Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\"}],\"isPrivate\":false,\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"stats\":[{\"avzone\":\"us-central-2a\",\"cluster\":\"jollyllama\",\"capacity\":0,\"qps\":0,\"throughput_in\":0,\"throughput_out\":0,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669d94b22eb8e51064490467\",\"name\":\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\"display_name\":\"Meta
        Llama 3.1 8B Instruct Turbo\",\"display_type\":\"chat\",\"description\":\"Llama
        3.1 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"Llama-3.1 (Other)\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":8000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":true,\"context_length\":32768,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\",\"<|eom_id|>\"],\"constraintVariants\":[{\"type\":\"json_schema\",\"model_name\":\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-vLLM\"},{\"type\":\"tools\",\"model_name\":\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"}],\"contextLengthVariants\":[{\"min_context\":16384,\"model_name\":\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-vLLM\"}],\"chat_template\":\"{{-
        bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools
        %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%-
        set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string
        is defined %}\\n    {%- set date_string = \\\"26 Jul 2024\\\" %}\\n{%- endif
        %}\\n\\n{#- This block extracts the system message, so we can slot it into
        the right place. #}\\n{%- if messages[0]['role'] == 'system' %}\\n    {%-
        set system_message = messages[0]['content']|trim %}\\n    {%- set messages
        = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \\\"\\\" %}\\n{%-
        endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \\\"<|start_header_id|>system<|end_header_id|>\\n\\n\\\"
        }}\\n{%- if builtin_tools is defined or tools %}\\n    {{- \\\"Environment:
        ipython\\n\\\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{-
        \\\"Tools: \\\" + builtin_tools | reject('equalto', 'code_interpreter') |
        join(\\\", \\\") + \\\"\\n\\n\\\"}}\\n{%- endif %}\\n{{- \\\"Cutting Knowledge
        Date: December 2023\\n\\\" }}\\n{{- \\\"Today Date: \\\" + date_string + \\\"\\n\\n\\\"
        }}\\n{%- if tools %}\\n    {{- \\\"You have access to the following functions:\\n\\n\\\"
        }}{%- for t in tools %}\\n        {{- \\\"Use the function '\\\" + t.function.name
        + \\\"' to '\\\" + t.function.description + \\\"'\\n\\\" }}\\n        {{-
        t.function | dump(4) }}\\n        {{- \\\"\\n\\n\\\" }}\\n    {%- endfor %}\\n{%
        raw %}If a you choose to call a function ONLY reply in the following format:\\n<{start_tag}={function_name}>{parameters}{end_tag}\\nwhere\\n\\nstart_tag
        => `<function`\\nparameters => a JSON dict with the function argument name
        as key and function argument value as value.\\nend_tag => `</function>`\\n\\nHere
        is an example,\\n<function=example_function_name>{\\\"example_name\\\": \\\"example_value\\\"}</function>\\n\\nReminder:\\n-
        Function calls MUST follow the specified format\\n- Required parameters MUST
        be specified\\n- Only call one function at a time\\n- Put the entire function
        call reply on one line\\n- Always add your sources when using search results
        to answer the user query\\n\\n{% endraw %}{%- endif %}\\n{{- system_message
        }}\\n{{- \\\"<|eot_id|>\\\" }}\\n\\n{%- for message in messages %}\\n    {%-
        if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls'
        in message) %}\\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+
        message['content'] | trim + '<|eot_id|>' }}\\n    {%- elif 'tool_calls' in
        message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{-
        raise_exception(\\\"This model only supports single tool-calls at once!\\\")
        }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function
        %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools
        %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        -}}\\n            {{- \\\"<|python_tag|>\\\" + tool_call.name + \\\".call(\\\"
        }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items
        %}\\n                {{- arg_name + '=\\\"' + arg_val + '\\\"' }}\\n                {%-
        if not loop.last %}\\n                    {{- \\\", \\\" }}\\n                {%-
        endif %}\\n                {%- endfor %}\\n            {{- \\\")\\\" }}\\n
        \       {%- else  %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        -}}\\n            {{- '{\\\"name\\\": \\\"' + tool_call.name + '\\\", ' }}\\n
        \           {{- '\\\"parameters\\\": ' }}\\n            {{- tool_call.arguments
        | dump }}\\n            {{- \\\"}\\\" }}\\n        {%- endif %}\\n        {%-
        if builtin_tools is defined %}\\n            {#- This means we're in ipython
        mode #}\\n            {{- \\\"<|eom_id|>\\\" }}\\n        {%- else %}\\n            {{-
        \\\"<|eot_id|>\\\" }}\\n        {%- endif %}\\n    {%- elif message.role ==
        \\\"tool\\\" or message.role == \\\"ipython\\\" %}\\n        {{- \\\"<|start_header_id|>ipython<|end_header_id|>\\n\\n\\\"
        }}\\n        {%- if message.content is mapping or message.content is iterable
        %}\\n            {{- message.content | dump }}\\n        {%- else %}\\n            {{-
        message.content }}\\n        {%- endif %}\\n        {{- \\\"<|eot_id|>\\\"
        }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n
        \   {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{%- endif
        %}\",\"tool_type\":\"llama3.1\",\"force_template\":true,\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|eot_id|>\",\"add_generation_prompt\":true,\"max_tokens\":2048},\"pricing\":{\"hourly\":0,\"input\":45,\"output\":45},\"created_at\":\"2024-07-21T23:07:30.740Z\",\"update_at\":\"2024-09-04T16:54:28.952Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"ca-east-1a\",\"cluster\":\"poutinepenguin\"},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"}],\"isPrivate\":false,\"access_control\":[{\"user_id\":\"65776b1c6943bff034b2248f\",\"role\":\"admin\"},{\"user_id\":\"63b8c450fc5f8b00a9eb88be\",\"role\":\"admin\"},{\"user_id\":\"65503d59c4e8d25c07854c0b\",\"role\":\"admin\"},{\"user_id\":\"63b46d7f108537a03cf0e2a4\",\"role\":\"admin\"},{\"user_id\":\"665e248837cb8a07b7dbd3cc\",\"role\":\"admin\"},{\"user_id\":\"66956c01ebc8ecf40784ec6a\",\"role\":\"admin\"},{\"user_id\":\"6684202b9a9836ec1f2ef970\",\"role\":\"admin\"},{\"user_id\":\"65e640b01a72659c1bede3d6\",\"role\":\"admin\"},{\"user_id\":\"64b58e15d947d0a7b785410a\",\"role\":\"admin\"},{\"user_id\":\"65d4fffb5bd967690b522117\",\"role\":\"admin\"},{\"user_id\":\"64ca98ed0f09c5c91516b39b\",\"role\":\"admin\"}],\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:turbo,category:LLAMA3\",\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":83.06666666666666,\"throughput_in\":313620,\"throughput_out\":18232.533333333333,\"stats\":[{\"avzone\":\"ca-east-1a\",\"cluster\":\"poutinepenguin\",\"capacity\":0.1483873996363525,\"qps\":42.2,\"throughput_in\":164722.26666666666,\"throughput_out\":9345.4,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0.14572698302315265,\"qps\":5.6,\"throughput_in\":22114.8,\"throughput_out\":1094.4666666666667,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0.13296859043022086,\"qps\":35.266666666666666,\"throughput_in\":126782.93333333333,\"throughput_out\":7792.666666666667,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669f0837449e35f33d8c8a8f\",\"name\":\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\"display_name\":\"Meta
        Llama 3.1 405B Instruct Turbo\",\"display_type\":\"chat\",\"description\":\"Llama
        3.1 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"llama\",\"link\":\"https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct\",\"creator_organization\":\"Meta\",\"num_parameters\":405000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"context_length\":4096,\"owner_userid\":\"\",\"config\":{\"stop\":[\"<|eot_id|>\",\"<|eom_id|>\"],\"constraintVariants\":[{\"type\":\"tools\",\"model_name\":\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\"}],\"chat_template\":\"{{-
        bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools
        %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%-
        set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string
        is defined %}\\n    {%- set date_string = \\\"26 Jul 2024\\\" %}\\n{%- endif
        %}\\n\\n{#- This block extracts the system message, so we can slot it into
        the right place. #}\\n{%- if messages[0]['role'] == 'system' %}\\n    {%-
        set system_message = messages[0]['content']|trim %}\\n    {%- set messages
        = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \\\"\\\" %}\\n{%-
        endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \\\"<|start_header_id|>system<|end_header_id|>\\n\\n\\\"
        }}\\n{%- if builtin_tools is defined or tools %}\\n    {{- \\\"Environment:
        ipython\\n\\\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{-
        \\\"Tools: \\\" + builtin_tools | reject('equalto', 'code_interpreter') |
        join(\\\", \\\") + \\\"\\n\\n\\\"}}\\n{%- endif %}\\n{{- \\\"Cutting Knowledge
        Date: December 2023\\n\\\" }}\\n{{- \\\"Today Date: \\\" + date_string + \\\"\\n\\n\\\"
        }}\\n{%- if tools %}\\n    {{- \\\"You have access to the following functions:\\n\\n\\\"
        }}{%- for t in tools %}\\n        {{- \\\"Use the function '\\\" + t.function.name
        + \\\"' to '\\\" + t.function.description + \\\"'\\n\\\" }}\\n        {{-
        t.function | dump(4) }}\\n        {{- \\\"\\n\\n\\\" }}\\n    {%- endfor %}\\n{%
        raw %}If a you choose to call a function ONLY reply in the following format:\\n<{start_tag}={function_name}>{parameters}{end_tag}\\nwhere\\n\\nstart_tag
        => `<function`\\nparameters => a JSON dict with the function argument name
        as key and function argument value as value.\\nend_tag => `</function>`\\n\\nHere
        is an example,\\n<function=example_function_name>{\\\"example_name\\\": \\\"example_value\\\"}</function>\\n\\nReminder:\\n-
        Function calls MUST follow the specified format\\n- Required parameters MUST
        be specified\\n- Only call one function at a time\\n- Put the entire function
        call reply on one line\\n- Always add your sources when using search results
        to answer the user query\\n\\n{% endraw %}{%- endif %}\\n{{- system_message
        }}\\n{{- \\\"<|eot_id|>\\\" }}\\n\\n{%- for message in messages %}\\n    {%-
        if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls'
        in message) %}\\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+
        message['content'] | trim + '<|eot_id|>' }}\\n    {%- elif 'tool_calls' in
        message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{-
        raise_exception(\\\"This model only supports single tool-calls at once!\\\")
        }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function
        %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools
        %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        -}}\\n            {{- \\\"<|python_tag|>\\\" + tool_call.name + \\\".call(\\\"
        }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items
        %}\\n                {{- arg_name + '=\\\"' + arg_val + '\\\"' }}\\n                {%-
        if not loop.last %}\\n                    {{- \\\", \\\" }}\\n                {%-
        endif %}\\n                {%- endfor %}\\n            {{- \\\")\\\" }}\\n
        \       {%- else  %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        -}}\\n            {{- '{\\\"name\\\": \\\"' + tool_call.name + '\\\", ' }}\\n
        \           {{- '\\\"parameters\\\": ' }}\\n            {{- tool_call.arguments
        | dump }}\\n            {{- \\\"}\\\" }}\\n        {%- endif %}\\n        {%-
        if builtin_tools is defined %}\\n            {#- This means we're in ipython
        mode #}\\n            {{- \\\"<|eom_id|>\\\" }}\\n        {%- else %}\\n            {{-
        \\\"<|eot_id|>\\\" }}\\n        {%- endif %}\\n    {%- elif message.role ==
        \\\"tool\\\" or message.role == \\\"ipython\\\" %}\\n        {{- \\\"<|start_header_id|>ipython<|end_header_id|>\\n\\n\\\"
        }}\\n        {%- if message.content is mapping or message.content is iterable
        %}\\n            {{- message.content | dump }}\\n        {%- else %}\\n            {{-
        message.content }}\\n        {%- endif %}\\n        {{- \\\"<|eot_id|>\\\"
        }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n
        \   {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{%- endif
        %}\",\"tool_type\":\"llama3.1\",\"force_template\":true,\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|eot_id|>\",\"add_generation_prompt\":true,\"max_tokens\":2048},\"pricing\":{\"hourly\":0,\"input\":1250,\"output\":1250},\"created_at\":\"2024-07-23T01:32:39.964Z\",\"update_at\":\"2024-09-06T16:07:24.108Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\"},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\"},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\"},{\"avzone\":\"ca-east-1a\",\"cluster\":\"poutinepenguin\"},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"}],\"isPrivate\":false,\"access_control\":[{\"user_id\":\"65776b1c6943bff034b2248f\",\"role\":\"admin\"},{\"user_id\":\"63b8c450fc5f8b00a9eb88be\",\"role\":\"admin\"},{\"user_id\":\"65503d59c4e8d25c07854c0b\",\"role\":\"admin\"},{\"user_id\":\"63b46d7f108537a03cf0e2a4\",\"role\":\"admin\"},{\"user_id\":\"665e248837cb8a07b7dbd3cc\",\"role\":\"admin\"},{\"user_id\":\"66956c01ebc8ecf40784ec6a\",\"role\":\"admin\"},{\"user_id\":\"6684202b9a9836ec1f2ef970\",\"role\":\"admin\"},{\"user_id\":\"65e640b01a72659c1bede3d6\",\"role\":\"admin\"},{\"user_id\":\"64b58e15d947d0a7b785410a\",\"role\":\"admin\"},{\"user_id\":\"65d4fffb5bd967690b522117\",\"role\":\"admin\"},{\"user_id\":\"63a0eca8a22da34e53ba2d48\",\"role\":\"admin\"},{\"user_id\":\"65987df6752090cead0c9056\",\"role\":\"admin\"}],\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:turbo,category:LLAMA3\",\"maxQpsAuthenticated\":20,\"maxQpsUnauthenticated\":0.1,\"maxQpsUserOverrides\":[{\"user_id\":\"65f039a945ac817c15e4977c\",\"max_qps\":20},{\"user_id\":\"657860f24a1a694374ae12be\",\"max_qps\":20}],\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":2.8000000000000003,\"throughput_in\":6823.533333333333,\"throughput_out\":276.9333333333333,\"stats\":[{\"avzone\":\"us-central-5b\",\"cluster\":\"blusterybull\",\"capacity\":0.20658448717392247,\"qps\":1.5333333333333334,\"throughput_in\":3552.9333333333334,\"throughput_out\":174.73333333333332,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-south-1a\",\"cluster\":\"mustymarfa\",\"capacity\":0,\"qps\":0.2,\"throughput_in\":609.1333333333333,\"throughput_out\":9.133333333333333,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-east-1a\",\"cluster\":\"happypiglet\",\"capacity\":0,\"qps\":0.6,\"throughput_in\":1450.2666666666667,\"throughput_out\":62.6,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"ca-east-1a\",\"cluster\":\"poutinepenguin\",\"capacity\":0.24490356931001056,\"qps\":0.06666666666666667,\"throughput_in\":135.86666666666667,\"throughput_out\":4.2,\"error_rate\":0,\"retry_rate\":0},{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0,\"qps\":0.4,\"throughput_in\":1075.3333333333333,\"throughput_out\":26.266666666666666,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66d79fe5dd97f32e306f1845\",\"name\":\"NousResearch/Hermes-3-Llama-3.1-405B-Turbo\",\"display_name\":\"Hermes
        3 - Llama-3.1 405B\",\"display_type\":\"chat\",\"description\":\"Hermes 3
        is a generalist language model with many improvements over Hermes 2, including
        advanced agentic capabilities, much better roleplaying, reasoning, multi-turn
        conversation, long context coherence, and improvements across the board\",\"license\":\"llama3\",\"link\":\"https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-405B
        \",\"creator_organization\":\"NousResearch\",\"num_parameters\":405000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":true,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{{bos_token}}{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] +
        '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n'
        }}{% endif %}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|im_end|>\",\"add_generation_prompt\":true},\"max_tokens\":8192,\"pricing\":{\"hourly\":0,\"input\":1250,\"output\":1250},\"created_at\":\"2024-09-04T01:08:37.875Z\",\"update_at\":\"2024-09-04T01:08:37.875Z\",\"has_wandb_telemetry\":false,\"instances\":[{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\"}],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"depth\":{\"num_asks\":1,\"num_bids\":0,\"num_running\":0,\"qps\":0.3333333333333333,\"throughput_in\":579.9333333333333,\"throughput_out\":41.266666666666666,\"stats\":[{\"avzone\":\"us-central-6a\",\"cluster\":\"mirthfulmonkey\",\"capacity\":0.08251768739962671,\"qps\":0.3333333333333333,\"throughput_in\":579.9333333333333,\"throughput_out\":41.266666666666666,\"error_rate\":0,\"retry_rate\":0}],\"error_rate\":0,\"retry_rate\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"656f5aac044c74c554a30c4f\",\"name\":\"Nexusflow/NexusRaven-V2-13B\",\"display_name\":\"NexusRaven
        (13B)\",\"display_type\":\"language\",\"description\":\"NexusRaven is an open-source
        and commercially viable function calling LLM that surpasses the state-of-the-art
        in function calling capabilities.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Nexusflow\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-12-05T17:15:24.561Z\",\"update_at\":\"2023-12-05T17:15:24.561Z\",\"instances\":[],\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6598bc0201bf780326e7eac8\",\"name\":\"bert-base-uncased\",\"display_name\":\"Bert
        Base Uncased\",\"display_type\":\"embedding\",\"description\":\"original BERT
        model\",\"license\":\"\",\"creator_organization\":\"Google\",\"hardware_label\":\"A40\",\"pricing_tier\":\"Featured\",\"num_parameters\":46550608,\"release_date\":\"2023-11-15T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"pricing\":{\"hourly\":0,\"input\":2,\"output\":2,\"finetune\":0,\"base\":0},\"created_at\":\"2024-01-06T02:33:38.323Z\",\"update_at\":\"2024-01-06T02:33:38.323Z\",\"instances\":[],\"lago_tag\":\"metricTag:EMBEDDING_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6567d4e5d1c5e59967640530\",\"name\":\"WizardLM/WizardLM-13B-V1.2\",\"display_name\":\"WizardLM
        v1.2 (13B)\",\"display_type\":\"chat\",\"description\":\"This model achieves
        a substantial and comprehensive improvement on coding, mathematical reasoning
        and open-domain conversation capacities\",\"license\":\"\",\"creator_organization\":\"WizardLM\",\"hardware_label\":\"A100\",\"pricing_tier\":\"Featured\",\"num_parameters\":13000000000,\"release_date\":\"2023-11-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\",\"USER:\",\"ASSISTANT:\"],\"prompt_format\":\"USER:
        {prompt} ASSISTANT:\",\"add_generation_prompt\":true,\"chat_template_name\":\"llama\",\"pre_prompt\":\"A
        chat between a curious user and an artificial intelligence assistant. The
        assistant gives helpful, detailed, and polite answers to the user's questions.
        \"},\"pricing\":{\"input\":50,\"output\":50},\"created_at\":\"2023-11-30T00:18:45.791Z\",\"update_at\":\"2023-11-30T01:20:01.779Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65d7ea3b03b97802d3af0514\",\"name\":\"google/gemma-7b\",\"display_name\":\"Gemma
        (7B)\",\"display_type\":\"language\",\"description\":\"Gemma is a family of
        lightweight, state-of-the-art open models from Google, built from the same
        research and technology used to create the Gemini models.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Google\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-02-23T00:43:39.642Z\",\"update_at\":\"2024-02-23T00:43:39.642Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64ace9ca227f790586239d09\",\"name\":\"togethercomputer/Koala-7B\",\"display_name\":\"Koala
        (7B)\",\"display_type\":\"chat\",\"description\":\"Chatbot trained by fine-tuning
        LLaMA on dialogue data gathered from the web.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"LM
        Sys\",\"hardware_label\":\"A40 48GB\",\"pricing_tier\":\"featured\",\"access\":\"open\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":\"USER:
        {prompt} GPT:\",\"chat_template\":\"{% for message in messages %}{% if message['role']
        == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: '
        + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-11T05:34:02.521Z\",\"update_at\":\"2023-07-11T05:34:02.521Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"656fa3548d9fd20968de9ba7\",\"name\":\"zero-one-ai/Yi-34B\",\"display_name\":\"01-ai
        Yi Base (34B)\",\"display_type\":\"language\",\"description\":\"The Yi series
        models are large language models trained from scratch by developers at 01.AI\",\"license\":\"\",\"creator_organization\":\"01.AI\",\"hardware_label\":\"A100\",\"pricing_tier\":\"Featured\",\"num_parameters\":34000000000,\"release_date\":\"2023-11-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"pricing\":{\"input\":200,\"output\":200},\"created_at\":\"2023-12-05T22:25:24.982Z\",\"update_at\":\"2023-12-05T22:51:15.306Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66a175865019524ebcb9e001\",\"name\":\"Qwen/Qwen2-1.5B-Instruct\",\"display_name\":\"Qwen
        2 Instruct (1.5B)\",\"display_type\":\"chat\",\"description\":\"Qwen2 is the
        new series of Qwen large language models. For Qwen2, we release a number of
        base language models and instruction-tuned language models ranging from 0.5
        to 72 billion parameters, including a Mixture-of-Experts model.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":1500000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"stop\":[\"<|im_start|>\",\"<|im_end|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] +
        '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n'
        }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":5,\"output\":5},\"created_at\":\"2024-06-07T20:36:01.437Z\",\"update_at\":\"2024-07-24T22:03:50.924Z\",\"has_wandb_telemetry\":false,\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65735df36923087ddd5a6607\",\"name\":\"togethercomputer/StripedHyena-Hessian-7B\",\"display_name\":\"StripedHyena
        Hessian (7B)\",\"display_type\":\"language\",\"description\":\"A hybrid architecture
        composed of multi-head, grouped-query attention and gated convolutions arranged
        in Hyena blocks, different from traditional decoder-only Transformers\",\"license\":\"\",\"creator_organization\":\"Together\",\"hardware_label\":\"H100\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"release_date\":\"2023-11-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"pricing\":{\"input\":50,\"output\":50},\"created_at\":\"2023-12-08T18:18:27.005Z\",\"update_at\":\"2023-12-08T19:03:32.567Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"653c053fd9679a84df55c4e7\",\"name\":\"teknium/OpenHermes-2-Mistral-7B\",\"display_name\":\"OpenHermes-2-Mistral
        (7B)\",\"display_type\":\"chat\",\"description\":\"State of the art Mistral
        Fine-tuned on extensive public datasets\",\"license\":\"\",\"creator_organization\":\"teknium\",\"hardware_label\":\"A40\",\"pricing_tier\":\"Featured\",\"num_parameters\":7241732096,\"release_date\":\"2023-10-27T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"config\":{\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"pre_prompt\":\"<|im_start|>system\\nYou
        are thoughtful, helpful, polite, honest, and friendly<|im_end|>\\n\",\"add_generation_prompt\":true,\"chat_template_name\":\"default\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-10-27T18:45:19.307Z\",\"update_at\":\"2023-10-27T23:53:05.438Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66a1886f5019524ebcb9e004\",\"name\":\"Qwen/Qwen2-7B-Instruct\",\"display_name\":\"Qwen
        2 Instruct (7B)\",\"display_type\":\"chat\",\"description\":\"Qwen2 is the
        new series of Qwen large language models. For Qwen2, we release a number of
        base language models and instruction-tuned language models ranging from 0.5
        to 72 billion parameters, including a Mixture-of-Experts model.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":72000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"stop\":[\"<|im_start|>\",\"<|im_end|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] +
        '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n'
        }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-06-07T20:36:01.437Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64acebb2227f790586239d16\",\"name\":\"NousResearch/Nous-Hermes-13b\",\"display_name\":\"Nous
        Hermes (13B)\",\"display_type\":\"language\",\"description\":\"LLaMA 13B fine-tuned
        on over 300,000 instructions. Designed for long responses, low hallucination
        rate, and absence of censorship mechanisms.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Nous
        Research\",\"hardware_label\":\"A40 48GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"chat_template_name\":\"llama\",\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n'
        + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-07-11T05:42:10.444Z\",\"update_at\":\"2023-07-11T05:42:10.444Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64ace8d1227f790586239d03\",\"name\":\"togethercomputer/guanaco-65b\",\"display_name\":\"Guanaco
        (65B) \",\"display_type\":\"chat\",\"description\":\"Instruction-following
        language model built on LLaMA. Expanding upon the initial 52K dataset from
        the Alpaca model, an additional 534,530 focused on multi-lingual tasks.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Tim
        Dettmers\",\"hardware_label\":\"2X A100 80GB\",\"pricing_tier\":\"Supported\",\"access\":\"open\",\"num_parameters\":65000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"###\"],\"prompt_format\":\"###
        Human: {prompt} ### Assistant:\",\"chat_template\":\"{% for message in messages
        %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content']
        + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif
        %}{% endfor %}{{ '### Assistant:' }}\"},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2023-07-11T05:29:53.740Z\",\"update_at\":\"2023-07-11T05:29:53.740Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64b7165fcccc52103e2f07e5\",\"name\":\"togethercomputer/llama-2-7b\",\"display_name\":\"LLaMA-2
        (7B)\",\"display_type\":\"language\",\"description\":\"Language model trained
        on 2 trillion tokens with double the context length of Llama 1. Available
        in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":6738415616,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-07-18T22:46:55.042Z\",\"renamed\":\"meta-llama/Llama-2-7b-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"664bc5d94eafbbbcbc05c598\",\"name\":\"hazyresearch/M2-BERT-2k-Retrieval-Encoder-V1\",\"display_name\":\"M2-BERT
        2K Retrieval Encoder V1 \",\"display_type\":\"embedding\",\"description\":\"Monarch
        Mixer-BERT from the Monarch Mixer paper fine-tuned for retrieval\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"HazyResearch\",\"num_parameters\":110698560,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"owner_userid\":null,\"config\":{},\"pricing\":{\"input\":2,\"output\":2,\"hourly\":0},\"created_at\":\"2024-05-20T21:51:21.573Z\",\"update_at\":\"2024-05-20T21:51:21.573Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:EMBEDDING_MODEL\",\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64acea6e227f790586239d0e\",\"name\":\"huggyllama/llama-7b\",\"display_name\":\"LLaMA
        (7B)\",\"display_type\":\"language\",\"description\":\"An auto-regressive
        language model, based on the transformer architecture. The model comes in
        different sizes: 7B, 13B, 33B and 65B parameters.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-11T05:36:46.255Z\",\"update_at\":\"2023-07-11T05:36:46.255Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"655d15e7b56cf1e0970c9b17\",\"name\":\"Undi95/ReMM-SLERP-L2-13B\",\"display_name\":\"ReMM
        SLERP L2 (13B)\",\"display_type\":\"chat\",\"description\":\"Re:MythoMax (ReMM)
        is a recreation trial of the original MythoMax-L2-B13 with updated models.
        This merge use SLERP [TESTING] to merge ReML and Huginn v1.2.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Undi95\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"prompt_format\":\"[INST]\\n
        {prompt} \\n[/INST]\\n\\n\",\"stop\":[\"[INST]\",\"\\n\\n\"],\"chat_template_name\":\"llama\",\"add_generation_prompt\":true},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-11-21T20:41:11.759Z\",\"update_at\":\"2023-11-21T20:41:11.759Z\",\"instances\":[],\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64acf013227f790586239d43\",\"name\":\"lmsys/vicuna-7b-v1.3\",\"display_name\":\"Vicuna
        v1.3 (7B)\",\"display_type\":\"chat\",\"description\":\"Chatbot trained by
        fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive
        model, based on the transformer architecture.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"LM
        Sys\",\"hardware_label\":\"A40 48GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":\"USER:
        {prompt}\\nASSISTANT:\",\"chat_template\":\"{% for message in messages %}{{message['role'].toLocaleUpperCase()
        + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-11T06:00:51.553Z\",\"update_at\":\"2023-07-11T06:00:51.553Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"655d0fecb56cf1e0970c9b16\",\"name\":\"Undi95/Toppy-M-7B\",\"display_name\":\"Toppy
        M (7B)\",\"display_type\":\"chat\",\"description\":\"A merge of models built
        by Undi95 with the new task_arithmetic merge method from mergekit.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Undi95\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":7241748480,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"###\"],\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n\\n### Response:\",\"chat_template\":\"{% for message
        in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' +
        message['content'] + '\\n\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-11-21T20:15:40.468Z\",\"update_at\":\"2023-11-21T20:15:40.468Z\",\"instances\":[],\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66a2d6f6943289cbfab8b775\",\"name\":\"Qwen/Qwen2-72B\",\"display_name\":\"Qwen
        2 (72B)\",\"display_type\":\"language\",\"description\":\"Qwen2 is the new
        series of Qwen large language models. For Qwen2, we release a number of base
        language models and instruction-tuned language models ranging from 0.5 to
        72 billion parameters, including a Mixture-of-Experts model.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":72000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"context_length\":32768,\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0},\"created_at\":\"2024-06-07T20:36:01.437Z\",\"update_at\":\"2024-08-06T14:06:32.982Z\",\"has_wandb_telemetry\":false,\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64fbbc5adfdb1e4b06b5d5cb\",\"name\":\"Phind/Phind-CodeLlama-34B-v2\",\"display_name\":\"Phind
        Code LLaMA v2 (34B)\",\"display_type\":\"code\",\"description\":\"Phind-CodeLlama-34B-v1
        trained on additional 1.5B tokens high-quality programming-related data proficient
        in Python, C/C++, TypeScript, Java, and more.\",\"license\":\"\",\"creator_organization\":\"Phind\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":33743970304,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"prompt_format\":\"###
        System Prompt\\nYou are an intelligent programming assistant.\\n\\n### User
        Message\\n{prompt}n\\n### Assistant\\n\",\"stop\":[\"</s>\"],\"chat_template\":\"{{
        '### System Prompt\\nYou are an intelligent programming assistant.\\n\\n'
        }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User
        Message\\n' + message['content'] + '\\n' }}{% else %}{{ '### Assistant\\n'
        + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant\\n'
        }}\"},\"pricing\":{\"input\":200,\"output\":200,\"hourly\":0},\"created_at\":\"2023-09-09T00:29:14.496Z\",\"update_at\":\"2023-09-09T00:29:14.496Z\",\"instances\":[],\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64fbbc5adfdb1e4b06b5d5cc\",\"name\":\"Phind/Phind-CodeLlama-34B-Python-v1\",\"display_name\":\"Phind
        Code LLaMA Python v1 (34B)\",\"display_type\":\"code\",\"description\":\"This
        model is fine-tuned from CodeLlama-34B-Python and achieves 69.5% pass@1 on
        HumanEval.\",\"license\":\"\",\"creator_organization\":\"Phind\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":33743970304,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n### Response:\\n\",\"stop\":[\"</s>\",\"###\"],\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n'
        + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"},\"pricing\":{\"input\":200,\"output\":200,\"hourly\":0},\"created_at\":\"2023-09-09T00:29:14.496Z\",\"update_at\":\"2023-09-09T00:29:14.496Z\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65ac4e5e75846d9d3ae5b836\",\"name\":\"NumbersStation/nsql-llama-2-7B\",\"display_name\":\"NSQL
        LLaMA-2 (7B)\",\"display_type\":\"code\",\"description\":\"NSQL is a family
        of autoregressive open-source large foundation models (FMs) designed specifically
        for SQL generation tasks\",\"link\":\"\",\"creator_organization\":\"Numbers
        Station\",\"hardware_label\":\"A100\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"release_date\":\"2024-01-20T22:51:10.492Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"pricing\":{\"hourly\":0,\"input\":50,\"output\":50,\"finetune\":0,\"base\":0},\"created_at\":\"2024-01-20T22:51:10.492Z\",\"update_at\":\"2024-01-20T22:59:48.333Z\",\"access\":\"\",\"license\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6532f0faf94bacfc629b4cf8\",\"name\":\"NousResearch/Nous-Hermes-Llama2-70b\",\"display_name\":\"Nous
        Hermes LLaMA-2 (70B)\",\"display_type\":\"chat\",\"description\":\"Nous-Hermes-Llama2-70b
        is a state-of-the-art language model fine-tuned on over 300,000 instructions.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"NousResearch\",\"hardware_label\":\"2X
        A100 80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"###\",\"</s>\"],\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n\\n### Response:\\n\",\"chat_template_name\":\"llama\",\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n'
        + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2023-10-20T21:28:26.404Z\",\"update_at\":\"2023-10-24T17:43:39.278Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64f67555bc372ce719b97f03\",\"name\":\"WizardLM/WizardLM-70B-V1.0\",\"display_name\":\"WizardLM
        v1.0 (70B)\",\"display_type\":\"language\",\"description\":\"This model achieves
        a substantial and comprehensive improvement on coding, mathematical reasoning
        and open-domain conversation capacities.\",\"license\":\"\",\"creator_organization\":\"WizardLM\",\"hardware_label\":\"2x
        A100 80GB\",\"pricing_tier\":\"supported\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":\"USER:
        {prompt} ASSISTANT:\",\"chat_template\":\"{% for message in messages %}{%
        if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{%
        else %}{{ 'ASSISTANT:' + message['content'] + '\\n' }}{% endif %}{% endfor
        %}{{ 'ASSISTANT:' }}\"},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2023-09-05T00:24:53.327Z\",\"update_at\":\"2023-09-05T00:24:53.327Z\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64acea57227f790586239d0d\",\"name\":\"huggyllama/llama-65b\",\"display_name\":\"LLaMA
        (65B)\",\"display_type\":\"language\",\"description\":\"An auto-regressive
        language model, based on the transformer architecture. The model comes in
        different sizes: 7B, 13B, 33B and 65B parameters.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"2x
        A100 80GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":65000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2023-07-11T05:36:23.656Z\",\"update_at\":\"2023-07-11T05:36:23.656Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64fbbc5adfdb1e4b06b5d5ce\",\"name\":\"lmsys/vicuna-13b-v1.5-16k\",\"display_name\":\"Vicuna
        v1.5 16K (13B)\",\"display_type\":\"chat\",\"description\":\"Vicuna is a chat
        assistant trained by fine-tuning Llama 2 on user-shared conversations collected
        from ShareGPT.\",\"license\":\"\",\"creator_organization\":\"LM Sys\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":13015864320,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"prompt_format\":\"USER:
        {prompt}\\nASSISTANT:\",\"stop\":[\"</s>\"],\"chat_template\":\"{% for message
        in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content']
        + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-09-09T00:29:14.496Z\",\"update_at\":\"2023-09-09T00:29:14.496Z\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"657b7a2a84ef58c3562de91e\",\"name\":\"openchat/openchat-3.5-1210\",\"display_name\":\"OpenChat
        3.5\",\"display_type\":\"chat\",\"description\":\"A merge of OpenChat 3.5
        was trained with C-RLFT on a collection of publicly available high-quality
        instruction data, with a custom processing pipeline.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"OpenChat\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"config\":{\"chat_template\":\"{{
        bos_token }}{% for message in messages %}{{ 'GPT4 Correct ' + message['role']
        + ': ' + message['content'] + '<|end_of_turn|>'}}{% endfor %}{% if add_generation_prompt
        %}{{ 'GPT4 Correct Assistant:' }}{% endif %}\",\"stop\":[\"<|end_of_turn|>\",\"</s>\"],\"add_generation_prompt\":true,\"bos_token\":\"<s>\",\"prompt_format\":\"GPT4
        Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-12-14T21:56:58.576Z\",\"update_at\":\"2023-12-14T21:56:58.576Z\",\"instances\":[],\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"657bed666aca120ac2af2fb7\",\"name\":\"HuggingFaceH4/zephyr-7b-beta\",\"display_name\":\"Zephyr-7B-\xDF\",\"display_type\":\"chat\",\"description\":\"A
        fine-tuned version of Mistral-7B to act as a helpful assistant.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"HuggingFace\",\"hardware_label\":\"2x
        A100 80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":7241732096,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"stop\":[\"[INST]\",\"</s>\"],\"prompt_format\":\"<s>[INST]
        {prompt} [INST]\"},\"created_at\":\"2023-12-15T06:08:38.925Z\",\"update_at\":\"2023-12-15T06:08:38.925Z\",\"descriptionLink\":\"\",\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0,\"base\":0,\"finetune\":0}},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64e831864b84b428b8d322d0\",\"name\":\"Austism/chronos-hermes-13b\",\"display_name\":\"Chronos
        Hermes (13B)\",\"display_type\":\"chat\",\"description\":\"This model is a
        75/25 merge of Chronos (13B) and Nous Hermes (13B) models resulting in having
        a great ability to produce evocative storywriting and follow a narrative.\",\"license\":\"\",\"creator_organization\":\"Austism\",\"hardware_label\":\"2x
        A100 80GB\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n### Response:\\n\",\"chat_template\":\"{% for message
        in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' +
        message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-08-24T17:08:25.379Z\",\"update_at\":\"2023-08-24T17:08:25.379Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c8164975e79f24d98b4f\",\"name\":\"Qwen/Qwen1.5-0.5B\",\"display_name\":\"Qwen
        1.5 (0.5B)\",\"display_type\":\"language\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":500000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{},\"pricing\":{\"input\":25,\"output\":25,\"hourly\":0},\"created_at\":\"2024-02-05T11:35:50.032Z\",\"update_at\":\"2024-02-05T11:35:50.032Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c8214975e79f24d98b51\",\"name\":\"Qwen/Qwen1.5-1.8B\",\"display_name\":\"Qwen
        1.5 (1.8B)\",\"display_type\":\"language\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":1800000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{},\"pricing\":{\"input\":25,\"output\":25,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:01.895Z\",\"update_at\":\"2024-02-05T11:36:01.895Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c82e4975e79f24d98b53\",\"name\":\"Qwen/Qwen1.5-4B\",\"display_name\":\"Qwen
        1.5 (4B)\",\"display_type\":\"language\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":4000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{},\"pricing\":{\"input\":25,\"output\":25,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:14.800Z\",\"update_at\":\"2024-02-05T11:36:14.800Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c83a4975e79f24d98b55\",\"name\":\"Qwen/Qwen1.5-7B\",\"display_name\":\"Qwen
        1.5 (7B)\",\"display_type\":\"language\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:26.420Z\",\"update_at\":\"2024-02-05T11:36:26.420Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65b454f3d9877b0bd1376470\",\"name\":\"snorkelai/Snorkel-Mistral-PairRM-DPO\",\"display_name\":\"Snorkel
        Mistral PairRM DPO (7B)\",\"display_type\":\"chat\",\"description\":\"A state-of-the-art
        model by Snorkel AI, DPO fine-tuned on Mistral-7B\",\"license\":\"\",\"creator_organization\":\"Snorkel
        AI\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"release_date\":\"2024-01-27T00:57:23.638Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"[/INST]\",\"</s>\"],\"chat_template_name\":\"llama\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-01-27T00:57:23.638Z\",\"update_at\":\"2024-01-27T14:24:41.745Z\",\"instances\":[],\"access\":\"\",\"hardware_label\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c84d4975e79f24d98b58\",\"name\":\"Qwen/Qwen1.5-14B-Chat\",\"display_name\":\"Qwen
        1.5 Chat (14B)\",\"display_type\":\"chat\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":14000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{%
        if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>'
        + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role']
        != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:45.529Z\",\"update_at\":\"2024-02-05T11:36:45.529Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c8544975e79f24d98b59\",\"name\":\"Qwen/Qwen1.5-72B\",\"display_name\":\"Qwen
        1.5 (72B)\",\"display_type\":\"language\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":72000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:52.008Z\",\"update_at\":\"2024-02-05T11:36:52.008Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c8284975e79f24d98b52\",\"name\":\"Qwen/Qwen1.5-1.8B-Chat\",\"display_name\":\"Qwen
        1.5 Chat (1.8B)\",\"display_type\":\"chat\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":1800000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{%
        if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>'
        + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role']
        != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":25,\"output\":25,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:08.609Z\",\"update_at\":\"2024-02-05T11:36:08.609Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"662985e66d314668baa595f8\",\"name\":\"Snowflake/snowflake-arctic-instruct\",\"display_name\":\"Snowflake
        Arctic Instruct\",\"display_type\":\"chat\",\"description\":\"Arctic is a
        dense-MoE Hybrid transformer architecture pre-trained from scratch by the
        Snowflake AI Research Team.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Snowflake\",\"hardware_label\":\"8X
        H100 80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":480000000000,\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"<|im_start|>\",\"<|im_end|>\"],\"add_generation_prompt\":true,\"chat_template_name\":\"default\",\"max_tokens\":2048},\"pricing\":{\"hourly\":0,\"input\":600,\"output\":600},\"update_at\":\"2024-05-21T04:34:51.453Z\",\"instances\":[],\"isPrivate\":false,\"isDedicatedInstance\":false,\"engine\":\"vllm\",\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64b7165fcccc52103e2f07e7\",\"name\":\"togethercomputer/llama-2-13b\",\"display_name\":\"LLaMA-2
        (13B)\",\"display_type\":\"language\",\"description\":\"Language model trained
        on 2 trillion tokens with double the context length of Llama 1. Available
        in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":13015864320,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":55,\"output\":55,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-12-04T05:07:52.318Z\",\"renamed\":\"meta-llama/Llama-2-13b-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a4466efbc8405400423166\",\"name\":\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\"display_name\":\"Nous
        Hermes 2 - Mixtral 8x7B-SFT\",\"display_type\":\"chat\",\"description\":\"Nous
        Hermes 2 Mixtral 7bx8 SFT is the new flagship Nous Research model trained
        over the Mixtral 7bx8 MoE LLM. The model was trained on over 1,000,000 entries
        of primarily GPT-4 generated data, as well as other high quality data from
        open datasets across the AI landscape, achieving state of the art performance
        on a variety of tasks.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"NousResearch\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":56000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"add_generation_prompt\":true,\"chat_template_name\":\"default\"},\"pricing\":{\"input\":150,\"output\":150,\"hourly\":0},\"created_at\":\"2024-01-14T20:39:10.060Z\",\"update_at\":\"2024-01-14T20:39:10.060Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"instances\":[],\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c3137e4975e79f24d98b5c\",\"name\":\"deepseek-ai/deepseek-coder-33b-instruct\",\"display_name\":\"Deepseek
        Coder Instruct (33B)\",\"display_type\":\"chat\",\"description\":\"Deepseek
        Coder is composed of a series of code language models, each trained from scratch
        on 2T tokens, with a composition of 87% code and 13% natural language in both
        English and Chinese.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"DeepSeek\",\"pricing_tier\":\"Featured\",\"num_parameters\":33000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"prompt_format\":\"\",\"stop\":[\"<|EOT|>\",\"<\uFF5Cbegin\u2581of\u2581sentence\uFF5C>\",\"<\uFF5Cend\u2581of\u2581sentence\uFF5C>\"],\"bos_token\":\"<\uFF5Cbegin\u2581of\u2581sentence\uFF5C>\",\"add_generation_prompt\":true,\"chat_template\":\"{{'<\uFF5Cbegin\u2581of\u2581sentence\uFF5C>'}}{%-
        for message in messages %}{%- if message['role'] == 'system' %}{{ message['content']
        }}{%- else %}{%- if message['role'] == 'user' %}{{'### Instruction:\\\\n'
        + message['content'] + '\\\\n'}}{%- else %}{{'### Response:\\\\n' + message['content']
        + '\\\\n<|EOT|>\\\\n'}}{%- endif %}{%- endif %}{%- endfor %}{% if add_generation_prompt
        %}{{'### Response:'}}{% endif %}\"},\"pricing\":{\"input\":200,\"output\":200,\"hourly\":0},\"created_at\":\"2024-02-07T05:22:06.809Z\",\"update_at\":\"2024-02-07T05:22:06.809Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64e78e89589782acafe1781d\",\"name\":\"togethercomputer/CodeLlama-7b-Instruct\",\"display_name\":\"Code
        Llama Instruct (7B)\",\"display_type\":\"chat\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":6738546688,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"</s>\",\"[INST]\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-08-24T17:08:25.379Z\",\"update_at\":\"2023-08-24T17:08:25.379Z\",\"renamed\":\"codellama/CodeLlama-7b-Instruct-hf\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6de95e620478cfa144260\",\"name\":\"codellama/CodeLlama-34b-Python-hf\",\"display_name\":\"Code
        Llama Python (34B)\",\"display_type\":\"code\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":34000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":194,\"output\":194,\"hourly\":0},\"created_at\":\"2023-08-24T17:28:42.172Z\",\"update_at\":\"2023-08-24T17:28:42.172Z\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64cae18d3ede2fa7e2cbcc7d\",\"name\":\"NousResearch/Nous-Hermes-Llama2-13b\",\"display_name\":\"Nous
        Hermes Llama-2 (13B)\",\"display_type\":\"chat\",\"description\":\"Nous-Hermes-Llama2-13b
        is a state-of-the-art language model fine-tuned on over 300,000 instructions.\",\"license\":\"\",\"creator_organization\":\"NousResearch\",\"hardware_label\":\"2x
        A100 80GB\",\"pricing_tier\":\"featured\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n### Response:\\n\",\"stop\":[\"###\",\"</s>\"],\"chat_template_name\":\"llama\",\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n'
        + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-08-02T23:06:53.926Z\",\"update_at\":\"2023-10-07T00:19:33.779Z\",\"instances\":[],\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64f678e7bc372ce719b97f06\",\"name\":\"lmsys/vicuna-13b-v1.5\",\"display_name\":\"Vicuna
        v1.5 (13B)\",\"display_type\":\"chat\",\"description\":\"Vicuna is a chat
        assistant trained by fine-tuning Llama 2 on user-shared conversations collected
        from ShareGPT.\",\"license\":\"\",\"creator_organization\":\"LM Sys\",\"hardware_label\":\"A40
        48GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":\"USER:
        {prompt}\\nASSISTANT:\",\"chat_template\":\"{% for message in messages %}{{message['role'].toLocaleUpperCase()
        + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-09-05T00:40:07.763Z\",\"update_at\":\"2023-09-05T00:40:07.763Z\",\"instances\":[],\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64f0de22caa9e2eb543b373b\",\"name\":\"togethercomputer/guanaco-13b\",\"display_name\":\"Guanaco
        (13B) \",\"display_type\":\"chat\",\"description\":\"Instruction-following
        language model built on LLaMA. Expanding upon the initial 52K dataset from
        the Alpaca model, an additional 534,530 focused on multi-lingual tasks.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Tim
        Dettmers\",\"hardware_label\":\"A40 48GB\",\"pricing_tier\":\"Supported\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"###\"],\"prompt_format\":\"###
        Human: {prompt} ### Assistant:\",\"chat_template\":\"{% for message in messages
        %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content']
        + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif
        %}{% endfor %}{{ '### Assistant:' }}\"},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-07-11T05:29:07.717Z\",\"update_at\":\"2023-07-11T05:29:07.717Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65b6f4ba752a299002ee4dc7\",\"name\":\"codellama/CodeLlama-70b-Python-hf\",\"display_name\":\"Code
        Llama Python (70B)\",\"display_type\":\"code\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\"]},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-01-29T00:43:38.396Z\",\"update_at\":\"2024-01-29T00:43:38.396Z\",\"instances\":[],\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64e7934a589782acafe17822\",\"name\":\"togethercomputer/CodeLlama-34b-Python\",\"display_name\":\"Code
        Llama Python (34B)\",\"display_type\":\"code\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":34000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":194,\"output\":194,\"hourly\":0},\"created_at\":\"2023-08-24T17:28:42.172Z\",\"update_at\":\"2023-08-24T17:28:42.172Z\",\"renamed\":\"codellama/CodeLlama-34b-Python-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64e7934a589782acafe17823\",\"name\":\"togethercomputer/CodeLlama-34b-Instruct\",\"display_name\":\"Code
        Llama Instruct (34B)\",\"display_type\":\"chat\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":34000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"</s>\",\"[INST]\"],\"chat_template_name\":\"llama\",\"tools_template\":\"{{
        '<<SYS>>\\\\n' + systemMessage['content'] + '\\\\n\\\\nYou can access the
        following functions. Use them if required -\\\\n' + tools + '\\\\n<</SYS>>\\\\n\\\\n'
        + message['content'] }}\"},\"pricing\":{\"input\":194,\"output\":194,\"hourly\":0},\"created_at\":\"2023-08-24T17:28:42.172Z\",\"update_at\":\"2023-08-24T17:28:42.172Z\",\"renamed\":\"codellama/CodeLlama-34b-Instruct-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64e7934a589782acafe17821\",\"name\":\"togethercomputer/CodeLlama-34b\",\"display_name\":\"Code
        Llama (34B)\",\"display_type\":\"code\",\"description\":\"Code Llama is a
        family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":34000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":194,\"output\":194,\"hourly\":0},\"created_at\":\"2023-08-24T17:28:42.172Z\",\"update_at\":\"2023-08-24T17:28:42.172Z\",\"renamed\":\"codellama/CodeLlama-34b-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64b7165fcccc52103e2f07e9\",\"name\":\"togethercomputer/llama-2-70b\",\"display_name\":\"LLaMA-2
        (70B)\",\"display_type\":\"language\",\"description\":\"Language model trained
        on 2 trillion tokens with double the context length of Llama 1. Available
        in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"2X
        A100 80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":68976648192,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-07-18T22:46:55.042Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"renamed\":\"meta-llama/Llama-2-70b-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6de95e620478cfa14425c\",\"name\":\"codellama/CodeLlama-13b-hf\",\"display_name\":\"Code
        Llama (13B)\",\"display_type\":\"code\",\"description\":\"Code Llama is a
        family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":13016028160,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":55,\"output\":55,\"hourly\":0},\"created_at\":\"2023-08-24T17:09:14.381Z\",\"update_at\":\"2023-12-21T01:12:38.916Z\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6de95e620478cfa14425b\",\"name\":\"codellama/CodeLlama-13b-Instruct-hf\",\"display_name\":\"Code
        Llama Instruct (13B)\",\"display_type\":\"chat\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":13016028160,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"add_generation_prompt\":true,\"stop\":[\"</s>\",\"[INST]\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":55,\"output\":55,\"hourly\":0},\"created_at\":\"2023-08-24T17:09:14.381Z\",\"update_at\":\"2023-12-04T05:01:42.539Z\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66a2d70d943289cbfab8b776\",\"name\":\"Qwen/Qwen2-7B\",\"display_name\":\"Qwen
        2 (7B)\",\"display_type\":\"language\",\"description\":\"Qwen2 is the new
        series of Qwen large language models. For Qwen2, we release a number of base
        language models and instruction-tuned language models ranging from 0.5 to
        72 billion parameters, including a Mixture-of-Experts model.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"context_length\":32768,\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0},\"created_at\":\"2024-06-07T20:36:01.437Z\",\"update_at\":\"2024-08-06T14:06:17.109Z\",\"has_wandb_telemetry\":false,\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66a2d724943289cbfab8b777\",\"name\":\"Qwen/Qwen2-1.5B\",\"display_name\":\"Qwen
        2 (1.5B)\",\"display_type\":\"language\",\"description\":\"Qwen2 is the new
        series of Qwen large language models. For Qwen2, we release a number of base
        language models and instruction-tuned language models ranging from 0.5 to
        72 billion parameters, including a Mixture-of-Experts model.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":1500000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"context_length\":32768,\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0},\"created_at\":\"2024-06-07T20:36:01.437Z\",\"update_at\":\"2024-07-24T22:03:50.924Z\",\"has_wandb_telemetry\":false,\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64e78eba589782acafe17820\",\"name\":\"togethercomputer/CodeLlama-13b-Instruct\",\"display_name\":\"Code
        Llama Instruct (13B)\",\"display_type\":\"chat\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"Featured\",\"num_parameters\":13016028160,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"</s>\",\"[INST]\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":55,\"output\":55,\"hourly\":0},\"created_at\":\"2023-08-24T17:09:14.381Z\",\"update_at\":\"2023-12-04T05:01:42.539Z\",\"renamed\":\"codellama/CodeLlama-13b-Instruct-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6dd03e620478cfa144255\",\"name\":\"meta-llama/Llama-2-13b-hf\",\"display_name\":\"LLaMA-2
        (13B)\",\"display_type\":\"language\",\"description\":\"Language model trained
        on 2 trillion tokens with double the context length of Llama 1. Available
        in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":13015864320,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\"]},\"pricing\":{\"input\":55,\"output\":55,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-12-04T05:07:52.318Z\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64b7165fcccc52103e2f07e8\",\"name\":\"togethercomputer/llama-2-13b-chat\",\"display_name\":\"LLaMA-2
        Chat (13B)\",\"display_type\":\"chat\",\"description\":\"Llama 2-chat leverages
        publicly available instruction datasets and over 1 million human annotations.
        Available in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":13015864320,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"[/INST]\",\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":55,\"output\":55,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-12-04T05:00:54.436Z\",\"renamed\":\"meta-llama/Llama-2-13b-chat-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64acefe5227f790586239d41\",\"name\":\"lmsys/vicuna-13b-v1.3\",\"display_name\":\"Vicuna
        v1.3 (13B)\",\"display_type\":\"chat\",\"description\":\"Chatbot trained by
        fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive
        model, based on the transformer architecture.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"LM
        Sys\",\"hardware_label\":\"A40 48GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":\"USER:
        {prompt}\\nASSISTANT:\",\"chat_template\":\"{% for message in messages %}{{message['role'].toLocaleUpperCase()
        + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-07-11T06:00:05.166Z\",\"update_at\":\"2023-07-15T03:08:44.173Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64acea0b227f790586239d0b\",\"name\":\"huggyllama/llama-13b\",\"display_name\":\"LLaMA
        (13B)\",\"display_type\":\"language\",\"description\":\"An auto-regressive
        language model, based on the transformer architecture. The model comes in
        different sizes: 7B, 13B, 33B and 65B parameters.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-07-11T05:35:07.955Z\",\"update_at\":\"2023-07-11T05:35:07.955Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64f672e8bc372ce719b97f02\",\"name\":\"WizardLM/WizardCoder-Python-34B-V1.0\",\"display_name\":\"WizardCoder
        Python v1.0 (34B)\",\"display_type\":\"code\",\"description\":\"This model
        empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct
        method to the domain of code.\",\"license\":\"\",\"creator_organization\":\"WizardLM\",\"hardware_label\":\"2x
        A100 80GB\",\"pricing_tier\":\"supported\",\"num_parameters\":34000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"config\":{\"stop\":[\"</s>\",\"###\"],\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n### Response:\\n\"},\"pricing\":{\"input\":200,\"output\":200,\"hourly\":0},\"created_at\":\"2023-09-05T00:14:32.365Z\",\"update_at\":\"2023-09-05T00:14:32.365Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64acea35227f790586239d0c\",\"name\":\"huggyllama/llama-30b\",\"display_name\":\"LLaMA
        (30B)\",\"display_type\":\"language\",\"description\":\"An auto-regressive
        language model, based on the transformer architecture. The model comes in
        different sizes: 7B, 13B, 33B and 65B parameters.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"access\":\"open\",\"num_parameters\":33000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":200,\"output\":200,\"hourly\":0},\"created_at\":\"2023-07-11T05:35:49.870Z\",\"update_at\":\"2023-07-11T05:35:49.870Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65d542a20af4aafc88716626\",\"name\":\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\"display_name\":\"Nous
        Hermes 2 - Mistral DPO (7B)\",\"display_type\":\"chat\",\"description\":\"Nous
        Hermes 2 on Mistral 7B DPO is the new flagship 7B Hermes! This model was DPO'd
        from Teknium/OpenHermes-2.5-Mistral-7B and has improved across the board on
        all benchmarks tested - AGIEval, BigBench Reasoning, GPT4All, and TruthfulQA.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"NousResearch\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"stop\":[\"<|im_end|>\"],\"chat_template\":\"{%
        for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']
        + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n'
        }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-02-21T00:24:02.387Z\",\"update_at\":\"2024-02-21T00:24:02.387Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64ace317227f790586239ce2\",\"name\":\"togethercomputer/alpaca-7b\",\"display_name\":\"Alpaca
        (7B)\",\"display_type\":\"chat\",\"description\":\"Fine-tuned from the LLaMA
        7B model on 52K instruction-following demonstrations. \",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Stanford\",\"hardware_label\":\"A40
        48GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"</s>\",\"###\"],\"add_generation_prompt\":true,\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n### Response:\\n\",\"chat_template\":\"{% for message
        in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' +
        message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-11T05:05:27.713Z\",\"update_at\":\"2023-07-11T05:05:27.713Z\",\"instances\":[],\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64f676f7bc372ce719b97f04\",\"name\":\"garage-bAInd/Platypus2-70B-instruct\",\"display_name\":\"Platypus2
        Instruct (70B)\",\"display_type\":\"chat\",\"description\":\"An instruction
        fine-tuned LLaMA-2 (70B) model by merging Platypus2 (70B) by garage-bAInd
        and LLaMA-2 Instruct v2 (70B) by upstage.\",\"license\":\"\",\"creator_organization\":\"garage-bAInd\",\"hardware_label\":\"2x
        A100 80GB\",\"pricing_tier\":\"featured\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\",\"###\"],\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n### Response:\\n\",\"add_generation_prompt\":true,\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'user' %} {{ '### Instruction:\\n'
        + message['content'] + '\\n' }}{% elif message['role'] == 'system' %}{{ '###
        System:\\n' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant'
        %}{{ '### Response:\\n' + message['content'] + '\\n'  }}{% endif %}{% if loop.last
        %}{{ '### Response:\\n' }}{% endif %}{% endfor %}\"},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2023-09-05T00:31:51.264Z\",\"update_at\":\"2023-09-07T01:46:29.338Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65d7ea3d03b97802d3af0515\",\"name\":\"google/gemma-7b-it\",\"display_name\":\"Gemma
        Instruct (7B)\",\"display_type\":\"chat\",\"description\":\"Gemma is a family
        of lightweight, state-of-the-art open models from Google, built from the same
        research and technology used to create the Gemini models.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Google\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"config\":{\"stop\":[\"<eos>\",\"<end_of_turn>\"],\"chat_template\":\"{{
        bos_token }}{% if (message['role'] == 'assistant') %}{% set role = 'model'
        %}{% else %}{% set role = message['role'] %}{% endif %}{% for message in messages
        %}{{'<start_of_turn>' + role + '\\n' + message['content'] + '<end_of_turn>'
        + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>model\\n'
        }}{% endif %}\",\"bos_token\":\"<bos>\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-02-23T00:43:41.936Z\",\"update_at\":\"2024-02-23T00:43:41.936Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6dda7e620478cfa144259\",\"name\":\"meta-llama/Llama-2-7b-chat-hf\",\"display_name\":\"LLaMA-2
        Chat (7B)\",\"display_type\":\"chat\",\"description\":\"Llama 2-chat leverages
        publicly available instruction datasets and over 1 million human annotations.
        Available in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":6738415616,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"[/INST]\",\"</s>\"],\"add_generation_prompt\":true,\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-07-18T22:46:55.042Z\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65dfa6ebd28dc68bcefec056\",\"name\":\"allenai/OLMo-7B\",\"display_name\":\"OLMo
        (7B)\",\"display_type\":\"language\",\"description\":\"The OLMo models are
        trained on the Dolma dataset\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"AllenAI\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-02-28T21:34:35.444Z\",\"update_at\":\"2024-02-28T21:34:35.444Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65df9fa4d28dc68bcefec054\",\"name\":\"allenai/OLMo-7B-Instruct\",\"display_name\":\"OLMo
        Instruct (7B)\",\"display_type\":\"chat\",\"description\":\"The OLMo models
        are trained on the Dolma dataset\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"AllenAI\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"eos_token\":\"<|endoftext|>\",\"prompt_format\":\"<|user|>\\n{prompt}\\n<|assistant|>\",\"stop\":[\"<|endoftext|>\"],\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'user' %}{{ '<|user|>\\n'
        + message['content'] + eos_token }}{% elif message['role'] == 'system' %}{{
        '<|system|>\\n' + message['content'] + eos_token }}{% elif message['role']
        == 'assistant' %}{{ '<|assistant|>\\n'  + message['content'] + eos_token }}{%
        endif %}{% if loop.last and add_generation_prompt %}{{ '<|assistant|>\\n'
        }}{% endif %}{% endfor %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-02-28T21:03:32.038Z\",\"update_at\":\"2024-02-28T21:03:32.038Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64ace8a3227f790586239d02\",\"name\":\"togethercomputer/guanaco-33b\",\"display_name\":\"Guanaco
        (33B) \",\"display_type\":\"chat\",\"description\":\"Instruction-following
        language model built on LLaMA. Expanding upon the initial 52K dataset from
        the Alpaca model, an additional 534,530 focused on multi-lingual tasks.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Tim
        Dettmers\",\"hardware_label\":\"A100 80GB\",\"pricing_tier\":\"Supported\",\"access\":\"open\",\"num_parameters\":33000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"###\"],\"prompt_format\":\"###
        Human: {prompt} ### Assistant:\",\"chat_template\":\"{% for message in messages
        %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content']
        + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif
        %}{% endfor %}{{ '### Assistant:' }}\"},\"pricing\":{\"input\":200,\"output\":200,\"hourly\":0},\"created_at\":\"2023-07-11T05:29:07.717Z\",\"update_at\":\"2023-07-11T05:29:07.717Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64ace9b1227f790586239d07\",\"name\":\"togethercomputer/Koala-13B\",\"display_name\":\"Koala
        (13B)\",\"display_type\":\"chat\",\"description\":\"Chatbot trained by fine-tuning
        LLaMA on dialogue data gathered from the web.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"LM
        Sys\",\"hardware_label\":\"A40 48GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"</s>\"],\"prompt_format\":\"USER:
        {prompt} GPT:\",\"chat_template\":\"{% for message in messages %}{% if message['role']
        == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: '
        + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}\"},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2023-07-11T05:33:37.737Z\",\"update_at\":\"2023-07-11T05:33:37.737Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64b7165fcccc52103e2f07e6\",\"name\":\"togethercomputer/llama-2-7b-chat\",\"display_name\":\"LLaMA-2
        Chat (7B)\",\"display_type\":\"chat\",\"description\":\"Llama 2-chat leverages
        publicly available instruction datasets and over 1 million human annotations.
        Available in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":6738415616,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"[/INST]\",\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-07-18T22:46:55.042Z\",\"renamed\":\"meta-llama/Llama-2-7b-chat-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"662b250e246deee9aefbcc50\",\"name\":\"togethercomputer/SOLAR-10.7B-Instruct-v1.0-int4\",\"display_name\":\"Upstage
        SOLAR Instruct v1 (11B)-Int4\",\"display_type\":\"chat\",\"description\":\"Built
        on the Llama2 architecture, SOLAR-10.7B incorporates the innovative Upstage
        Depth Up-Scaling\",\"license\":\"\",\"creator_organization\":\"upstage\",\"hardware_label\":\"A100B\",\"pricing_tier\":\"Featured\",\"num_parameters\":10700000000,\"release_date\":\"2023-12-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"add_generation_prompt\":true,\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"chat_template\":\"{%
        for message in messages %}{{'<|im_start|>'}}{% if message['role'] == 'user'
        %}{{'user\\n' + message['content'] + '<|im_end|>\\n'}}{% elif message['role']
        == 'assistant' %}{{'assistant\\n' + message['content'] + '<|im_end|>\\n'}}{%
        elif message['role'] == 'system' %}{{'system\\n' + message['content'] + '<|im_end|>\\n'}}{%
        endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n'
        }}{% endif %}\"},\"pricing\":{\"input\":75,\"output\":75},\"created_at\":\"2024-04-26T03:52:46.866Z\",\"update_at\":\"2024-04-26T03:52:46.866Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64ace8ed227f790586239d04\",\"name\":\"togethercomputer/guanaco-7b\",\"display_name\":\"Guanaco
        (7B) \",\"display_type\":\"chat\",\"description\":\"Instruction-following
        language model built on LLaMA. Expanding upon the initial 52K dataset from
        the Alpaca model, an additional 534,530 focused on multi-lingual tasks. \",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Tim
        Dettmers\",\"hardware_label\":\"A40 48GB\",\"access\":\"open\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"config\":{\"stop\":[\"###\"],\"prompt_format\":\"###
        Human: {prompt} ### Assistant:\",\"chat_template\":\"{% for message in messages
        %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content']
        + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif
        %}{% endfor %}{{ '### Assistant:' }}\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-11T05:30:21.531Z\",\"update_at\":\"2023-07-11T05:30:21.531Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6532f0faf94bacfc629b4cf5\",\"name\":\"Open-Orca/Mistral-7B-OpenOrca\",\"display_name\":\"OpenOrca
        Mistral (7B) 8K\",\"display_type\":\"chat\",\"description\":\"An OpenOrca
        dataset fine-tune on top of Mistral 7B by the OpenOrca team.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"OpenOrca\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":7241748480,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"config\":{\"stop\":[\"<|im_end|>\"],\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"add_generation_prompt\":true,\"chat_template_name\":\"default\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-10-20T21:28:26.403Z\",\"update_at\":\"2023-10-24T00:01:52.541Z\",\"instances\":[],\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"660c40783cd92bc225de4b41\",\"name\":\"Qwen/Qwen1.5-32B\",\"display_name\":\"Qwen
        1.5 (32B)\",\"display_type\":\"language\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":32000000000,\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{},\"pricing\":{\"hourly\":0,\"input\":200,\"output\":200},\"created_at\":\"2024-04-02T17:23:42.826Z\",\"update_at\":\"2024-05-17T04:43:13.412Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6532f0faf94bacfc629b4cf7\",\"name\":\"EleutherAI/llemma_7b\",\"display_name\":\"Llemma
        (7B)\",\"display_type\":\"language\",\"description\":\"Llemma 7B is a language
        model for mathematics. It was initialized with Code Llama 7B weights, and
        trained on the Proof-Pile-2 for 200B tokens.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"EleutherAI\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":6738546688,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-10-20T21:28:26.403Z\",\"update_at\":\"2023-10-24T17:42:38.630Z\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6532f0faf94bacfc629b4cf6\",\"name\":\"NousResearch/Nous-Hermes-llama-2-7b\",\"display_name\":\"Nous
        Hermes LLaMA-2 (7B)\",\"display_type\":\"chat\",\"description\":\"Nous-Hermes-Llama2-7b
        is a state-of-the-art language model fine-tuned on over 300,000 instructions.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"NousResearch\",\"hardware_label\":\"A100
        80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":6738415616,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"prompt_format\":\"###
        Instruction:\\n{prompt}\\n### Response:\\n\",\"stop\":[\"###\",\"</s>\"],\"add_generation_prompt\":true,\"chat_template_name\":\"llama\",\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n'
        + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content']
        + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-10-20T21:28:26.403Z\",\"update_at\":\"2023-10-24T17:41:52.365Z\",\"instances\":[],\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"660c48d16184ee782ae490f0\",\"name\":\"Qwen/Qwen1.5-32B-Chat\",\"display_name\":\"Qwen
        1.5 Chat (32B)\",\"display_type\":\"chat\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":32000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{%
        if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>'
        + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role']
        != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":200,\"output\":200,\"hourly\":0},\"created_at\":\"2024-04-02T17:23:42.826Z\",\"update_at\":\"2024-04-05T15:40:08.892Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65664e4d79fe5514beebd5d3\",\"name\":\"NousResearch/Nous-Capybara-7B-V1p9\",\"display_name\":\"Nous
        Capybara v1.9 (7B)\",\"display_type\":\"chat\",\"description\":\"first Nous
        collection of dataset and models made by fine-tuning mostly on data created
        by Nous in-house\",\"license\":\"\",\"creator_organization\":\"NousResearch\",\"hardware_label\":\"A100\",\"pricing_tier\":\"Featured\",\"num_parameters\":7241732096,\"release_date\":\"2023-11-15T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"config\":{\"add_generation_prompt\":true,\"stop\":[\"USER:\",\"ASSISTANT:\"],\"prompt_format\":\"USER:\\n{prompt}\\nASSISTANT:\",\"chat_template\":\"{%
        for message in messages %}{% if message['role'] == 'user' %} {{ 'USER:\\n'
        + message['content'] + '\\n' }}{% elif message['role'] == 'system' %}{{ 'SYSTEM:\\n'
        + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{
        'ASSISTANT:\\n' + message['content'] + '\\n'  }}{% endif %}{% if loop.last
        %}{{ 'ASSISTANT:\\n' }}{% endif %}{% endfor %}\"},\"pricing\":{\"input\":50,\"output\":50},\"created_at\":\"2023-11-28T20:32:13.026Z\",\"update_at\":\"2023-11-28T20:33:03.163Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6620db134b2da307838b7cf2\",\"name\":\"meta-llama/Meta-Llama-3-70B\",\"display_name\":\"Meta
        Llama 3 70B\",\"display_type\":\"language\",\"description\":\"Llama 3 is an
        auto-regressive language model that uses an optimized transformer architecture.
        The tuned versions use supervised fine-tuning (SFT) and reinforcement learning
        with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":70000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"owner_userid\":null,\"config\":null,\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-04-18T08:34:27.131Z\",\"update_at\":\"2024-04-18T08:34:27.131Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6620db1d4b2da307838b7cf3\",\"name\":\"meta-llama/Llama-3-8b-hf\",\"display_name\":\"Meta
        Llama 3 8B\",\"display_type\":\"language\",\"description\":\"Llama 3 is an
        auto-regressive language model that uses an optimized transformer architecture.
        The tuned versions use supervised fine-tuning (SFT) and reinforcement learning
        with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":8000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"owner_userid\":null,\"config\":null,\"pricing\":{\"hourly\":0,\"input\":50,\"output\":50},\"created_at\":\"2024-04-18T08:34:37.676Z\",\"update_at\":\"2024-07-23T15:11:31.665Z\",\"has_wandb_telemetry\":false,\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65460075c5ce2e5fa70d6721\",\"name\":\"sentence-transformers/msmarco-bert-base-dot-v5\",\"display_name\":\"Sentence-BERT\",\"display_type\":\"embedding\",\"description\":\"A
        sentence-transformers model: it maps sentences & paragraphs to a 768 dimensional
        dense vector space and was designed for semantic search.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Together\",\"hardware_label\":\"L40\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":110000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":512,\"pricing\":{\"hourly\":0,\"input\":2,\"output\":2,\"finetune\":0,\"base\":0},\"created_at\":\"2023-11-04T08:27:33.867Z\",\"update_at\":\"2023-12-22T03:15:44.832Z\",\"instances\":[],\"lago_tag\":\"metricTag:EMBEDDING_MODEL\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6570718281b9e1cf0455ec53\",\"name\":\"zero-one-ai/Yi-6B\",\"display_name\":\"01-ai
        Yi Base (6B)\",\"display_type\":\"language\",\"description\":\"The Yi series
        models are large language models trained from scratch by developers at 01.AI\",\"license\":\"\",\"creator_organization\":\"01.AI\",\"hardware_label\":\"A100\",\"pricing_tier\":\"Featured\",\"num_parameters\":6000000000,\"release_date\":\"2023-11-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"pricing\":{\"input\":50,\"output\":50},\"created_at\":\"2023-12-06T13:05:06.567Z\",\"update_at\":\"2023-12-06T13:07:50.190Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66316415c3b4aab9202b12df\",\"name\":\"meta-llama/Meta-Llama-3-8B-Instruct\",\"serviceName\":\"meta-llama/Llama-3-8b-chat-hf\",\"display_name\":\"Meta
        Llama 3 8B Instruct\",\"display_type\":\"chat\",\"description\":\"Llama 3
        is an auto-regressive language model that uses an optimized transformer architecture.
        The tuned versions use supervised fine-tuning (SFT) and reinforcement learning
        with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-04-18T06:07:59.041Z\",\"update_at\":\"2024-04-24T19:14:26.075Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"652da26579174a6bc507647f\",\"name\":\"lmsys/vicuna-7b-v1.5\",\"display_name\":\"Vicuna
        v1.5 (7B)\",\"display_type\":\"chat\",\"description\":\"Vicuna is a chat assistant
        trained by fine-tuning Llama 2 on user-shared conversations collected from
        ShareGPT.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"LM Sys\",\"hardware_label\":\"A40
        48GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":6738415616,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\",\"USER:\"],\"add_generation_prompt\":true,\"prompt_format\":\"USER:
        {prompt}\\nASSISTANT: Hello!\",\"chat_template\":\"{% for message in messages
        %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{%
        endfor %}{{ 'ASSISTANT:' }}\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-10-16T20:51:49.194Z\",\"update_at\":\"2023-10-16T20:51:49.194Z\",\"instances\":[],\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64ace3af227f790586239ce6\",\"name\":\"wavymulder/Analog-Diffusion\",\"display_name\":\"Analog
        Diffusion\",\"display_type\":\"image\",\"description\":\"Dreambooth model
        trained on a diverse set of analog photographs to provide an analog film effect.
        \",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Wavymulder\",\"hardware_label\":\"A40
        48GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":0,\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"external_pricing_url\":\"https://www.together.xyz/apis#pricing\",\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0,\"finetune\":0,\"base\":0},\"created_at\":\"2023-07-11T05:07:59.364Z\",\"update_at\":\"2024-05-22T22:41:40.508Z\",\"instances\":[],\"isPrivate\":false,\"isDedicatedInstance\":false,\"engine\":\"image\",\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6de96e620478cfa144262\",\"name\":\"codellama/CodeLlama-34b-hf\",\"display_name\":\"Code
        Llama (34B)\",\"display_type\":\"code\",\"description\":\"Code Llama is a
        family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":34000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":194,\"output\":194,\"hourly\":0},\"created_at\":\"2023-08-24T17:28:42.172Z\",\"update_at\":\"2023-08-24T17:28:42.172Z\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"6495ff1312907e072b8aece1\",\"name\":\"runwayml/stable-diffusion-v1-5\",\"display_name\":\"Stable
        Diffusion 1.5\",\"display_type\":\"image\",\"description\":\"Latent text-to-image
        diffusion model capable of generating photo-realistic images given any text
        input.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Runway
        ML\",\"hardware_label\":\"A100 80GB\",\"pricing_tier\":\"featured\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"external_pricing_url\":\"https://www.together.xyz/apis#pricing\",\"config\":{\"height\":512,\"width\":512,\"number_of_images\":2,\"steps\":20,\"seed\":42},\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0,\"finetune\":0,\"base\":0},\"created_at\":\"2023-06-23T20:22:43.572Z\",\"update_at\":\"2024-05-23T20:45:43.938Z\",\"instances\":[],\"isPrivate\":false,\"isDedicatedInstance\":false,\"engine\":\"image\",\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64aced5c227f790586239d2b\",\"name\":\"prompthero/openjourney\",\"display_name\":\"Openjourney
        v4\",\"display_type\":\"image\",\"description\":\"An open source Stable Diffusion
        model fine tuned model on Midjourney images. \",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Prompt
        Hero\",\"hardware_label\":\"A40 48GB\",\"pricing_tier\":\"featured\",\"access\":\"open\",\"num_parameters\":13000000000,\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"external_pricing_url\":\"https://www.together.xyz/apis#pricing\",\"config\":{\"height\":512,\"width\":512,\"number_of_images\":2,\"steps\":20,\"seed\":42},\"pricing\":{\"hourly\":0,\"input\":75,\"output\":75},\"created_at\":\"2023-07-11T05:49:16.586Z\",\"update_at\":\"2024-05-23T20:54:38.912Z\",\"instances\":[],\"isPrivate\":false,\"isDedicatedInstance\":false,\"engine\":\"image\",\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6db78e620478cfa144254\",\"name\":\"meta-llama/Llama-2-7b-hf\",\"display_name\":\"LLaMA-2
        (7B)\",\"display_type\":\"language\",\"description\":\"Language model trained
        on 2 trillion tokens with double the context length of Llama 1. Available
        in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":6738415616,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"</s>\"]},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-07-18T22:46:55.042Z\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64acee11227f790586239d36\",\"name\":\"SG161222/Realistic_Vision_V3.0_VAE\",\"display_name\":\"Realistic
        Vision 3.0\",\"display_type\":\"image\",\"description\":\"Fine-tune version
        of Stable Diffusion focused on photorealism.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"SG161222\",\"hardware_label\":\"A40
        48GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"external_pricing_url\":\"https://www.together.xyz/apis#pricing\",\"config\":{\"height\":1024,\"width\":1024,\"number_of_images\":2,\"steps\":20,\"seed\":42},\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0,\"finetune\":0,\"base\":0},\"created_at\":\"2023-07-11T05:52:17.219Z\",\"update_at\":\"2024-05-23T20:19:09.740Z\",\"instances\":[],\"isPrivate\":false,\"isDedicatedInstance\":false,\"engine\":\"image\",\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"656a79054d805f78df5fd530\",\"name\":\"zero-one-ai/Yi-34B-Chat\",\"display_name\":\"01-ai
        Yi Chat (34B)\",\"display_type\":\"chat\",\"description\":\"The Yi series
        models are large language models trained from scratch by developers at 01.AI\",\"license\":\"\",\"creator_organization\":\"01.AI\",\"hardware_label\":\"A100\",\"pricing_tier\":\"Featured\",\"num_parameters\":34000000000,\"release_date\":\"2023-11-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"add_generation_prompt\":true,\"stop\":[\"<|im_start|>\",\"<|im_end|>\"],\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"chat_template_name\":\"default\"},\"pricing\":{\"input\":200,\"output\":200,\"base\":0},\"created_at\":\"2023-12-02T00:23:33.685Z\",\"update_at\":\"2023-12-02T00:26:55.827Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66316309c3b4aab9202b12de\",\"name\":\"meta-llama/Meta-Llama-3-70B-Instruct\",\"serviceName\":\"meta-llama/Llama-3-70b-chat-hf\",\"display_name\":\"Meta
        Llama 3 70B Instruct\",\"display_type\":\"chat\",\"description\":\"Llama 3
        is an auto-regressive language model that uses an optimized transformer architecture.
        The tuned versions use supervised fine-tuning (SFT) and reinforcement learning
        with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"owner_userid\":null,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-04-18T08:33:56.492Z\",\"update_at\":\"2024-04-24T19:06:49.423Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"665a6fc497c7c4bc481aa629\",\"name\":\"meta-llama/Llama-3-70b-hf\",\"display_name\":\"Meta
        Llama 3 70B HF\",\"display_type\":\"language\",\"description\":\"Llama 3 is
        an auto-regressive language model that uses an optimized transformer architecture.
        The tuned versions use supervised fine-tuning (SFT) and reinforcement learning
        with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"num_parameters\":70000000000,\"release_date\":\"\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"owner_userid\":null,\"config\":null,\"pricing\":{\"hourly\":0,\"input\":225,\"output\":225},\"created_at\":\"2024-04-18T08:34:27.131Z\",\"update_at\":\"2024-06-28T00:52:26.871Z\",\"renamed\":\"meta-llama/Meta-Llama-3-70B\",\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64e78e89589782acafe1781c\",\"name\":\"togethercomputer/CodeLlama-7b-Python\",\"display_name\":\"Code
        Llama Python (7B)\",\"display_type\":\"code\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":6738546688,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-08-24T17:08:25.379Z\",\"update_at\":\"2023-08-24T17:08:25.379Z\",\"renamed\":\"codellama/CodeLlama-7b-Python-hf\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65b6f4d4752a299002ee4dc8\",\"name\":\"codellama/CodeLlama-70b-hf\",\"display_name\":\"Code
        Llama (70B)\",\"display_type\":\"code\",\"description\":\"Code Llama is a
        family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"]},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-01-29T00:44:04.149Z\",\"update_at\":\"2024-01-29T00:44:04.149Z\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64c28e8742fa06a9511509d1\",\"name\":\"togethercomputer/LLaMA-2-7B-32K\",\"display_name\":\"LLaMA-2-32K
        (7B)\",\"display_type\":\"language\",\"description\":\"Extending LLaMA-2 to
        32K context, built with Meta's Position Interpolation and Together AI's data
        recipe and system optimizations.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Together\",\"hardware_label\":\"2x
        A100 80GB\",\"pricing_tier\":\"supported\",\"access\":\"open\",\"num_parameters\":6738415616,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"stop\":[\"\\n\\n\\n\\n\",\"<|endoftext|>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-07-27T15:34:31.581Z\",\"update_at\":\"2023-08-17T17:07:36.346Z\",\"instances\":[],\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65b6f505752a299002ee4dc9\",\"name\":\"codellama/CodeLlama-70b-Instruct-hf\",\"display_name\":\"Code
        Llama Instruct (70B)\",\"display_type\":\"chat\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":70000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"stop\":[\"<step>\"],\"chat_template\":\"{{
        bos_token + ' ' }}{% for message in messages %}{{'Source: ' + message['role'].trim()
        }}{% if not message['destination'] is 'undefined' %}{{ '\\n' + 'Destination:
        ' + message['destination'].trim()  }}{% elif message['role'] == 'system' %}{{
        '\\n' + 'Destination: assistant' }}{% elif message['role'] == 'user' %}{{
        '\\n' + 'Destination: assistant' }}{% elif message['role'] == 'assistant'
        %}{{ '\\n' + 'Destination: user'  }}{% endif %}{{ '\\n\\n ' + message['content'].trim()
        + '<step>'  + ' '}}{% endfor %}{% if add_generation_prompt %}{{ 'Source: assistant'
        + '\\n' }}{{ 'Destination: user' + '\\n\\n' + ' '  }}{% endif %}\",\"bos_token\":\"<s>\",\"step_id\":\"<step>\",\"add_generation_prompt\":true},\"pricing\":{\"hourly\":0,\"input\":225,\"output\":225},\"created_at\":\"2024-01-29T00:44:53.513Z\",\"update_at\":\"2024-08-09T19:29:02.493Z\",\"has_wandb_telemetry\":false,\"instances\":[],\"isPrivate\":false,\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66884888b657bbb853b47f83\",\"name\":\"NousResearch/Hermes-2-Theta-Llama-3-70B\",\"display_name\":\"Hermes
        2 Theta Llama-3 70B\",\"display_type\":\"chat\",\"description\":\"Hermes-2
        \u0398 (Theta) 70B is the continuation of our experimental merged model released
        by Nous Research, in collaboration with Charles Goddard and Arcee AI, the
        team behind MergeKit.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"NousResearch\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"owner_userid\":\"\",\"config\":{\"stop\":[\"<|im_end|>\"],\"chat_template\":\"{{bos_token}}{%
        for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']
        + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n'
        }}{% endif %}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|im_end|>\",\"add_generation_prompt\":true},\"pricing\":{\"input\":0,\"output\":0,\"hourly\":0},\"created_at\":\"2024-07-05T19:24:56.743Z\",\"update_at\":\"2024-07-05T19:24:56.743Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64acef00227f790586239d3b\",\"name\":\"stabilityai/stable-diffusion-2-1\",\"display_name\":\"Stable
        Diffusion 2.1\",\"display_type\":\"image\",\"description\":\"Latent text-to-image
        diffusion model capable of generating photo-realistic images given any text
        input.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Stability
        AI\",\"hardware_label\":\"A100 80GB\",\"pricing_tier\":\"featured\",\"show_in_playground\":true,\"finetuning_supported\":false,\"isFeaturedModel\":false,\"external_pricing_url\":\"https://www.together.xyz/apis#pricing\",\"pricing\":{\"hourly\":0,\"input\":0,\"output\":0,\"finetune\":0,\"base\":0},\"created_at\":\"2023-06-23T20:22:43.572Z\",\"update_at\":\"2024-05-28T16:36:01.842Z\",\"instances\":[],\"isPrivate\":false,\"isDedicatedInstance\":false,\"engine\":\"image\",\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65b40661251b2ff9f146d8ba\",\"name\":\"microsoft/phi-2\",\"display_name\":\"Microsoft
        Phi-2\",\"display_type\":\"language\",\"description\":\"Phi-2 is a Transformer
        with 2.7 billion parameters. It was trained using the same data sources as
        Phi-1.5, augmented with a new data source that consists of various NLP synthetic
        texts and filtered websites (for safety and educational value)\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Microsoft\",\"pricing_tier\":\"Featured\",\"num_parameters\":2700000000,\"release_date\":\"2024-01-26T19:22:09.533Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":2048,\"pricing\":{\"input\":25,\"output\":25,\"hourly\":0},\"created_at\":\"2024-01-26T19:22:09.533Z\",\"update_at\":\"2024-01-26T19:23:46.072Z\",\"instances\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c8404975e79f24d98b56\",\"name\":\"Qwen/Qwen1.5-7B-Chat\",\"display_name\":\"Qwen
        1.5 Chat (7B)\",\"display_type\":\"chat\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":7000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{%
        if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>'
        + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role']
        != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:32.804Z\",\"update_at\":\"2024-02-05T11:36:32.804Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"660899dc98fbb3f86d028781\",\"name\":\"cognitivecomputations/dolphin-2.5-mixtral-8x7b\",\"display_name\":\"Dolphin
        2.5 Mixtral 8x7b\",\"display_type\":\"chat\",\"description\":\"This Dolphin
        is really good at coding, I trained with a lot of coding data. It is very
        obedient but it is not DPO tuned - so you still might need to encourage it
        in the system prompt as I show in the below examples.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"cognitivecomputations\",\"hardware_label\":\"8x
        H100 80GB SXM\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":56000000000,\"release_date\":\"2023-08-01T00:00:00.000Z\",\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"pre_prompt\":\"<|im_start|>system\\nYou
        are Dolphin, an uncensored and unbiased AI assistant.<|im_end|>\\n\",\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"add_generation_prompt\":true,\"chat_template_name\":\"default\"},\"pricing\":{\"input\":150,\"output\":150,\"hourly\":0},\"created_at\":\"2023-09-05T19:58:25.683Z\",\"update_at\":\"2023-09-05T19:58:25.683Z\",\"instances\":[],\"isDedicatedInstance\":false,\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65df8df823e6726c2d053851\",\"name\":\"togethercomputer/evo-1-131k-base\",\"display_name\":\"Evo-1
        Base (131K)\",\"display_type\":\"language\",\"description\":\"Evo is a biological
        foundation model capable of long-context modeling and design. Evo uses the
        StripedHyena architecture to enable modeling of sequences at a single-nucleotide,
        byte-level resolution with near-linear scaling of compute and memory relative
        to context length. Evo has 7 billion parameters and is trained on OpenGenome,
        a prokaryotic whole-genome dataset containing ~300 billion tokens.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Together\",\"pricing_tier\":\"Featured\",\"num_parameters\":6450000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":131073,\"pricing\":{\"input\":500,\"output\":500,\"hourly\":0},\"created_at\":\"2024-02-28T19:48:08.106Z\",\"update_at\":\"2024-02-28T19:48:08.106Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"lago_tag\":\"metricTag:GENOMIC_MODEL\",\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65df8d9623e6726c2d053850\",\"name\":\"togethercomputer/evo-1-8k-base\",\"display_name\":\"Evo-1
        Base (8K)\",\"display_type\":\"language\",\"description\":\"Evo is a biological
        foundation model capable of long-context modeling and design. Evo uses the
        StripedHyena architecture to enable modeling of sequences at a single-nucleotide,
        byte-level resolution with near-linear scaling of compute and memory relative
        to context length. Evo has 7 billion parameters and is trained on OpenGenome,
        a prokaryotic whole-genome dataset containing ~300 billion tokens.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Together\",\"pricing_tier\":\"Featured\",\"num_parameters\":6450000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"pricing\":{\"input\":500,\"output\":500,\"hourly\":0},\"created_at\":\"2024-02-28T19:46:30.585Z\",\"update_at\":\"2024-04-19T18:58:00.962Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"lago_tag\":\"metricTag:GENOMIC_MODEL\",\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64e78eba589782acafe1781f\",\"name\":\"togethercomputer/CodeLlama-13b-Python\",\"display_name\":\"Code
        Llama Python (13B)\",\"display_type\":\"code\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":13016028160,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":55,\"output\":55,\"hourly\":0},\"created_at\":\"2023-08-24T17:09:14.381Z\",\"update_at\":\"2023-12-20T22:52:59.177Z\",\"renamed\":\"codellama/CodeLlama-13b-Python-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6de95e620478cfa14425f\",\"name\":\"codellama/CodeLlama-7b-hf\",\"display_name\":\"Code
        Llama (7B)\",\"display_type\":\"code\",\"description\":\"Code Llama is a family
        of large language models for code based on Llama 2 providing infilling capabilities,
        support for large input contexts, and zero-shot instruction following ability
        for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":6738546688,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-08-24T17:08:25.379Z\",\"update_at\":\"2023-08-24T17:08:25.379Z\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"64b7165fcccc52103e2f07ea\",\"name\":\"togethercomputer/llama-2-70b-chat\",\"display_name\":\"LLaMA-2
        Chat (70B)\",\"display_type\":\"chat\",\"description\":\"Llama 2-chat leverages
        publicly available instruction datasets and over 1 million human annotations.
        Available in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"2X
        A100 80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":68976648192,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"[/INST]\",\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2023-07-18T22:46:55.042Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"renamed\":\"meta-llama/Llama-2-70b-chat-hf\",\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c8474975e79f24d98b57\",\"name\":\"Qwen/Qwen1.5-14B\",\"display_name\":\"Qwen
        1.5 (14B)\",\"display_type\":\"language\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":14000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{},\"pricing\":{\"input\":75,\"output\":75,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:39.431Z\",\"update_at\":\"2024-02-05T11:36:39.431Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6de95e620478cfa14425a\",\"name\":\"codellama/CodeLlama-13b-Python-hf\",\"display_name\":\"Code
        Llama Python (13B)\",\"display_type\":\"code\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":13016028160,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":55,\"output\":55,\"hourly\":0},\"created_at\":\"2023-08-24T17:09:14.381Z\",\"update_at\":\"2023-12-20T22:52:59.177Z\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c81b4975e79f24d98b50\",\"name\":\"Qwen/Qwen1.5-0.5B-Chat\",\"display_name\":\"Qwen
        1.5 Chat (0.5B)\",\"display_type\":\"chat\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":500000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{%
        if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>'
        + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role']
        != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":25,\"output\":25,\"hourly\":0},\"created_at\":\"2024-02-05T11:35:55.571Z\",\"update_at\":\"2024-02-05T11:35:55.571Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6de95e620478cfa14425e\",\"name\":\"codellama/CodeLlama-7b-Instruct-hf\",\"display_name\":\"Code
        Llama Instruct (7B)\",\"display_type\":\"chat\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":6738546688,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"</s>\",\"[INST]\"],\"chat_template_name\":\"llama\",\"add_generation_prompt\":true},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-08-24T17:08:25.379Z\",\"update_at\":\"2023-08-24T17:08:25.379Z\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"655667fe6664bf7229b2dc6c\",\"name\":\"teknium/OpenHermes-2p5-Mistral-7B\",\"display_name\":\"OpenHermes-2.5-Mistral
        (7B)\",\"display_type\":\"chat\",\"description\":\"Continuation of OpenHermes
        2 Mistral model trained on additional code datasets\",\"license\":\"\",\"creator_organization\":\"teknium\",\"hardware_label\":\"A40\",\"pricing_tier\":\"Featured\",\"num_parameters\":7241732096,\"release_date\":\"2023-11-15T00:00:00.000Z\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"config\":{\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"add_generation_prompt\":true,\"chat_template_name\":\"default\"},\"pricing\":{\"input\":50,\"output\":50},\"created_at\":\"2023-11-16T19:05:34.976Z\",\"update_at\":\"2023-11-16T19:12:24.883Z\",\"instances\":[],\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65d7e93203b97802d3af0513\",\"name\":\"google/gemma-2b\",\"display_name\":\"Gemma
        (2B)\",\"display_type\":\"language\",\"description\":\"Gemma is a family of
        lightweight, state-of-the-art open models from Google, built from the same
        research and technology used to create the Gemini models.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Google\",\"pricing_tier\":\"Featured\",\"num_parameters\":2000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"pricing\":{\"input\":25,\"output\":25,\"hourly\":0},\"created_at\":\"2024-02-23T00:39:14.772Z\",\"update_at\":\"2024-02-23T00:39:14.772Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65c0c8344975e79f24d98b54\",\"name\":\"Qwen/Qwen1.5-4B-Chat\",\"display_name\":\"Qwen
        1.5 Chat (4B)\",\"display_type\":\"chat\",\"description\":\"Qwen1.5 is the
        beta version of Qwen2, a transformer-based decoder-only language model pretrained
        on a large amount of data. In comparison with the previous released Qwen.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Qwen\",\"pricing_tier\":\"Featured\",\"num_parameters\":4000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":32768,\"config\":{\"prompt_format\":\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\",\"stop\":[\"<|im_end|>\",\"<|im_start|>\"],\"chat_template\":\"{%
        for message in messages %}{% if loop.first and messages[0]['role'] != 'system'
        %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{%
        endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{%
        if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>'
        + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role']
        != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\"add_generation_prompt\":true},\"pricing\":{\"input\":25,\"output\":25,\"hourly\":0},\"created_at\":\"2024-02-05T11:36:20.314Z\",\"update_at\":\"2024-02-05T11:36:20.314Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"66165fa701f2f8a98997bf8e\",\"name\":\"mistralai/Mixtral-8x22B\",\"display_name\":\"Mixtral-8x22B\",\"display_type\":\"language\",\"description\":\"The
        Mixtral-8x22B Large Language Model (LLM) is a pretrained generative Sparse
        Mixture of Experts.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"mistralai\",\"pricing_tier\":\"Featured\",\"num_parameters\":138000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":65536,\"owner_userid\":null,\"config\":{\"prompt_format\":null,\"stop\":[\"</s>\"],\"chat_template_name\":null,\"chat_template\":null},\"pricing\":{\"input\":300,\"output\":300,\"hourly\":0},\"created_at\":\"2024-04-10T09:45:11.291Z\",\"update_at\":\"2024-04-10T09:45:11.291Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"lago_tag\":\"metricTag:MIXTRAL_MODEL\",\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6dd95e620478cfa144257\",\"name\":\"meta-llama/Llama-2-70b-chat-hf\",\"display_name\":\"LLaMA-2
        Chat (70B)\",\"display_type\":\"chat\",\"description\":\"Llama 2-chat leverages
        publicly available instruction datasets and over 1 million human annotations.
        Available in three sizes: 7B, 13B and 70B parameters\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"2X
        A100 80GB\",\"pricing_tier\":\"Featured\",\"access\":\"open\",\"num_parameters\":68976648192,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":4096,\"config\":{\"prompt_format\":\"[INST]
        {prompt} [/INST]\",\"stop\":[\"[/INST]\",\"</s>\"],\"add_generation_prompt\":true,\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2023-07-18T22:46:55.042Z\",\"update_at\":\"2024-04-19T01:11:44.938Z\",\"autopilot_pool\":\"cr-a100-80-2x\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"65a6de95e620478cfa14425d\",\"name\":\"codellama/CodeLlama-7b-Python-hf\",\"display_name\":\"Code
        Llama Python (7B)\",\"display_type\":\"code\",\"description\":\"Code Llama
        is a family of large language models for code based on Llama 2 providing infilling
        capabilities, support for large input contexts, and zero-shot instruction
        following ability for programming tasks.\",\"license\":\"\",\"creator_organization\":\"Meta\",\"hardware_label\":\"A100
        80GB\",\"num_parameters\":6738546688,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":16384,\"config\":{\"stop\":[\"</s>\"],\"chat_template_name\":\"llama\"},\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2023-08-24T17:08:25.379Z\",\"update_at\":\"2023-08-24T17:08:25.379Z\",\"instances\":[],\"lago_tag\":\"metricTag:LLAMA_2_MODEL\",\"access\":\"\",\"link\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669f4a28cecfa259fb91978a\",\"name\":\"carson/ml318br\",\"display_name\":\"carson
        ml318br\",\"display_type\":\"chat\",\"description\":\"carson\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"carson\",\"pricing_tier\":null,\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-07-21T23:07:30.740Z\",\"update_at\":\"2024-07-21T23:07:30.740Z\",\"instances\":[],\"isPrivate\":true,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669f4b4ccecfa259fb91978e\",\"name\":\"meta-llama/Meta-Llama-3.1-8B-Reference\",\"display_name\":\"Meta
        Llama 3.1 8B\",\"display_type\":\"language\",\"description\":\"Llama 3.1 is
        an auto-regressive language model that uses an optimized transformer architecture.
        The tuned versions use supervised fine-tuning (SFT) and reinforcement learning
        with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":8000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"pricing\":{\"input\":50,\"output\":50,\"hourly\":0},\"created_at\":\"2024-07-21T23:07:30.740Z\",\"update_at\":\"2024-07-21T23:07:30.740Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[{\"user_id\":\"65776b1c6943bff034b2248f\",\"role\":\"admin\"},{\"user_id\":\"63b8c450fc5f8b00a9eb88be\",\"role\":\"admin\"},{\"user_id\":\"65503d59c4e8d25c07854c0b\",\"role\":\"admin\"},{\"user_id\":\"63b46d7f108537a03cf0e2a4\",\"role\":\"admin\"},{\"user_id\":\"665e248837cb8a07b7dbd3cc\",\"role\":\"admin\"}],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"668dbd375c20d511118e2bc7\",\"name\":\"gradientai/Llama-3-70B-Instruct-Gradient-1048k\",\"display_name\":\"Llama-3
        70B Instruct Gradient 1048K\",\"display_type\":\"chat\",\"description\":\"This
        model extends LLama-3 70B's context length from 8k to > 1048K\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"gradientai\",\"num_parameters\":70000000000,\"show_in_playground\":true,\"isFeaturedModel\":false,\"context_length\":1048576,\"owner_userid\":\"\",\"config\":{\"stop\":[\"<|end_of_text|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt
        %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|end_of_text|>\",\"add_generation_prompt\":true},\"pricing\":{\"input\":0,\"output\":0,\"hourly\":0},\"created_at\":\"2024-07-05T19:24:56.743Z\",\"update_at\":\"2024-07-05T19:24:56.743Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669fd7c9cecfa259fb9197a4\",\"name\":\"meta-llama/Meta-Llama-3.1-70B-Instruct-Reference\",\"display_name\":\"Meta
        Llama 3.1 70B Instruct\",\"display_type\":\"chat\",\"description\":\"Llama
        3.1 is an auto-regressive language model that uses an optimized transformer
        architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement
        learning with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":70000000000,\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"config\":{\"stop\":[\"<|eot_id|>\"],\"chat_template\":\"{%
        set loop_messages = messages %}{% for message in loop_messages %}{% set content
        = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content']
        | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token
        + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n'
        }}\",\"bos_token\":\"<|begin_of_text|>\",\"eos_token\":\"<|eot_id|>\",\"add_generation_prompt\":true},\"pricing\":{\"input\":225,\"output\":225,\"hourly\":0},\"created_at\":\"2024-07-21T23:07:30.740Z\",\"update_at\":\"2024-07-21T23:07:30.740Z\",\"instances\":[],\"isPrivate\":false,\"access_control\":[{\"user_id\":\"65776b1c6943bff034b2248f\",\"role\":\"admin\"},{\"user_id\":\"63b8c450fc5f8b00a9eb88be\",\"role\":\"admin\"},{\"user_id\":\"65503d59c4e8d25c07854c0b\",\"role\":\"admin\"},{\"user_id\":\"63b46d7f108537a03cf0e2a4\",\"role\":\"admin\"},{\"user_id\":\"665e248837cb8a07b7dbd3cc\",\"role\":\"admin\"}],\"isDedicatedInstance\":false,\"isSelfServeDedicatedInstance\":false,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:turbo,category:LLAMA3\",\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"},{\"modelInstanceConfig\":{\"appearsIn\":[],\"order\":0},\"_id\":\"669fd87bcecfa259fb9197a5\",\"name\":\"meta-llama/Meta-Llama-3.1-70B-Reference\",\"display_name\":\"Meta
        Llama 3.1 70B\",\"display_type\":\"language\",\"description\":\"Llama 3.1
        is an auto-regressive language model that uses an optimized transformer architecture.
        The tuned versions use supervised fine-tuning (SFT) and reinforcement learning
        with human feedback (RLHF) to align with human preferences for helpfulness
        and safety.\",\"license\":\"\",\"link\":\"\",\"creator_organization\":\"Meta\",\"pricing_tier\":null,\"num_parameters\":70000000000,\"release_date\":\"\",\"show_in_playground\":true,\"finetuning_supported\":true,\"isFeaturedModel\":false,\"context_length\":8192,\"pricing\":{\"hourly\":0,\"input\":225,\"output\":225},\"created_at\":\"2024-07-21T23:07:30.740Z\",\"update_at\":\"2024-09-04T17:20:48.849Z\",\"has_wandb_telemetry\":false,\"instances\":[],\"isPrivate\":false,\"access_control\":[{\"user_id\":\"65776b1c6943bff034b2248f\",\"role\":\"admin\"},{\"user_id\":\"63b8c450fc5f8b00a9eb88be\",\"role\":\"admin\"},{\"user_id\":\"65503d59c4e8d25c07854c0b\",\"role\":\"admin\"},{\"user_id\":\"63b46d7f108537a03cf0e2a4\",\"role\":\"admin\"},{\"user_id\":\"665e248837cb8a07b7dbd3cc\",\"role\":\"admin\"}],\"isDedicatedInstance\":false,\"isByom\":false,\"isSelfServeDedicatedInstance\":false,\"isFinetuned\":false,\"lago_tag\":\"metricTag:TOKEN_PRICING,engine:turbo,category:LLAMA3\",\"access\":\"\",\"hardware_label\":\"\",\"descriptionLink\":\"\"}]"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c076c4cebc1befb-LHR
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Mon, 09 Sep 2024 13:11:15 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      alt-svc:
      - h3=":443"; ma=86400
      etag:
      - '"nfu3646hhl5217"'
      vary:
      - Accept-Encoding
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 4096, "messages": [{"role": "user", "content": "Two names
      for a pet pelican, be brief"}], "model": "claude-3-opus-20240229", "temperature":
      1.0, "stream": true}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      anthropic-version:
      - '2023-06-01'
      connection:
      - keep-alive
      content-length:
      - '175'
      content-type:
      - application/json
      host:
      - api.anthropic.com
      user-agent:
      - Anthropic/Python 0.34.2
      x-api-key:
      - sk-...
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 0.34.2
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.5
      x-stainless-stream-helper:
      - messages
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: '{"type":"error","error":{"type":"authentication_error","message":"invalid
        x-api-key"}}'
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c076c512d6294c6-LHR
      Connection:
      - keep-alive
      Content-Length:
      - '86'
      Content-Type:
      - application/json
      Date:
      - Mon, 09 Sep 2024 13:11:15 GMT
      Server:
      - cloudflare
      X-Robots-Tag:
      - none
      request-id:
      - req_01EFfgbcut5FgnsoyWMfRXoe
      via:
      - 1.1 google
      x-cloud-trace-context:
      - 7e17dd721e45a589d06271eeb165a5fb
      x-should-retry:
      - 'false'
    status:
      code: 401
      message: Unauthorized
version: 1
